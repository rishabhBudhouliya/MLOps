{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Launching a Jupyter Notebook Manually on Chameleon\n",
        "1. Go to the Chameleon Dashboard\n",
        "Visit: https://www.chameleoncloud.org/\n",
        "\n",
        "Sign in and choose your project allocation (if you’re in a project group, select the correct one)\n",
        "\n",
        "2. Launch a Jupyter Environment\n",
        "In the top menu, click \"User Interfaces\" → \"Jupyter\"\n",
        "\n",
        "Choose your site (e.g., UC/TACC/CHI@TACC)\n",
        "\n",
        "Click \"Launch Jupyter\"\n",
        "\n",
        "Select a CUDA-enabled environment (like CC-Ubuntu24.04-CUDA or CC-Ubuntu20.04-CUDA)\n",
        "\n",
        "Under Extra Options, you can specify:\n",
        "\n",
        "Number of vCPUs (4–8 is fine)\n",
        "\n",
        "RAM (16GB+ recommended)\n",
        "\n",
        "GPU (A100 if available and you plan to fine-tune)\n",
        "\n",
        "3. Once It’s Launched\n",
        "You’ll be redirected to a JupyterLab interface\n",
        "\n",
        "Open a terminal inside JupyterLab\n",
        "\n",
        "Clone your repo (or download notebooks directly):\n",
        "\n",
        "bash\n",
        "Copy\n",
        "Edit\n",
        "git clone https://github.com/your-username/your-repo.git\n",
        "cd your-repo\n"
      ],
      "metadata": {
        "id": "AwdS5R320DZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bring up a GPU server\n",
        "\n",
        "At the beginning of the lease time, we will bring up our GPU server. We will use the `python-chi` Python API to Chameleon to provision our server.\n",
        "\n",
        "We will execute the cells in this notebook inside the Chameleon Jupyter environment.\n",
        "\n",
        "Run the following cell, and make sure the correct project is selected:"
      ],
      "metadata": {
        "id": "hDL7NwIYx7Ob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8EKIQ6yxhYc"
      },
      "outputs": [],
      "source": [
        "from chi import server, context, lease\n",
        "import os\n",
        "\n",
        "context.version = \"1.0\"\n",
        "context.choose_project()\n",
        "context.choose_site(default=\"CHI@UC\")\n",
        "Change the string in the following cell to reflect the name of *your* lease (**with your own net ID**), then run it to get your lease:\n",
        "l = lease.get_lease(f\"llm_netID\") # or llm_single_netID, or llm_multi_netID\n",
        "l.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The status should show as “ACTIVE” now that we are past the lease start time.\n",
        "\n",
        "The rest of this notebook can be executed without any interactions from you, so at this point, you can save time by clicking on this cell, then selecting Run \\> Run Selected Cell and All Below from the Jupyter menu.\n",
        "\n",
        "As the notebook executes, monitor its progress to make sure it does not get stuck on any execution error, and also to see what it is doing!\n",
        "We will use the lease to bring up a server with the `CC-Ubuntu24.04-CUDA` disk image. (Note that the reservation information is passed when we create the instance!) This will take up to 10 minutes."
      ],
      "metadata": {
        "id": "zfuztI7KyE4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "username = os.getenv('USER') # all exp resources will have this prefix\n",
        "s = server.Server(\n",
        "    f\"node-llm-{username}\",\n",
        "    reservation_id=l.node_reservations[0][\"id\"],\n",
        "    image_name=\"CC-Ubuntu24.04-CUDA\"\n",
        ")\n",
        "s.submit(idempotent=True)\n",
        "Note: security groups are not used at Chameleon bare metal sites, so we do not have to configure any security groups on this instance.\n",
        "Then, we’ll associate a floating IP with the instance, so that we can access it over SSH.\n",
        "s.associate_floating_ip()\n",
        "s.refresh()\n",
        "s.check_connectivity()\n",
        "s.refresh()\n",
        "s.show(type=\"widget\")"
      ],
      "metadata": {
        "id": "rLlEVkmjyHsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Docker with NVIDIA container toolkit\n",
        "\n",
        "To use common deep learning frameworks like Tensorflow or PyTorch, we can run containers that have all the prerequisite libraries necessary for these frameworks. Here, we will set up the container framework."
      ],
      "metadata": {
        "id": "rRhasFyIyOrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s.execute(\"curl -sSL https://get.docker.com/ | sudo sh\")\n",
        "s.execute(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")\n",
        "s.execute(\"docker run hello-world\")"
      ],
      "metadata": {
        "id": "08s4VxU-yQs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also install the NVIDIA container toolkit, with which we can access GPUs from inside our containers.\n"
      ],
      "metadata": {
        "id": "jThD1pvyyVpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get NVIDIA container toolkit\n",
        "s.execute(\"curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
        "  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n",
        "    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n",
        "    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\")\n",
        "s.execute(\"sudo apt update\")\n",
        "s.execute(\"sudo apt-get install -y nvidia-container-toolkit\")\n",
        "s.execute(\"sudo nvidia-ctk runtime configure --runtime=docker\")\n",
        "s.execute(\"sudo systemctl restart docker\")\n"
      ],
      "metadata": {
        "id": "PucqFrcwyZtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell, we will verify that we can see our NVIDIA GPUs from inside a container, by passing `--gpus-all`. (The `-rm` flag says to clean up the container and remove its filesystem when it finishes running.)\n"
      ],
      "metadata": {
        "id": "9lu27RViybEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s.execute(\"docker run --rm --gpus all ubuntu nvidia-smi\")"
      ],
      "metadata": {
        "id": "-qiPAmiiycqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pull and start container\n",
        "\n",
        "Let’s pull the container:\n"
      ],
      "metadata": {
        "id": "mnZM9VYhykh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s.execute(\"docker pull quay.io/jupyter/pytorch-notebook:cuda12-pytorch-2.5.1\")\n"
      ],
      "metadata": {
        "id": "z6u-nuWbyiz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and get it running:"
      ],
      "metadata": {
        "id": "XLxkz7TTyzyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s.execute(\"docker run -d -p 8888:8888 --gpus all --name torchnb quay.io/jupyter/pytorch-notebook:cuda12-pytorch-2.5.1\")\n"
      ],
      "metadata": {
        "id": "XylwS46RyyGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There’s one more thing we must do before we can start out Jupyter server. Rather than expose the Jupyter server to the Internet, we are going to set up an SSH tunnel from our local terminal to our server, and access the service through that tunnel.\n",
        "\n",
        "Here’s how it works: In your *local* terminal, run\n",
        "\n",
        "    ssh -L 8888:127.0.0.1:8888 -i ~/.ssh/id_rsa_chameleon cc@A.B.C.D\n",
        "\n",
        "where,\n",
        "\n",
        "-   instead of `~/.ssh/id_rsa_chameleon`, substitute the path to your key\n",
        "-   and instead of `A.B.C.D`, substitute the floating IP associated with your server\n",
        "\n",
        "This will configure the SSH session so that when you connect to port 8888 locally, it will be forwarded over the SSH tunnel to port 8888 on the host at the other end of the SSH connection.\n",
        "\n",
        "SSH tunneling is a convenient way to access services on a remote machine when you don’t necessarily want to expose those services to the Internet (for example: if they are not secured from unauthorized access).\n",
        "Finally, run\n",
        "s.execute(\"docker logs torchnb\")\n",
        "Look for the line of output in the form:\n",
        "\n",
        "    http://127.0.0.1:8888/lab?token=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
        "\n",
        "and copy it for use."
      ],
      "metadata": {
        "id": "s2gOZKeiy1_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A4GBYl9rzZ99"
      }
    }
  ]
}