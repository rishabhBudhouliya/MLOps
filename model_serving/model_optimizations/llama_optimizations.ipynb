{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc6e203-7aa8-4dee-82e6-28be0a766a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip, json, time\n",
    "import torch \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    TrainingArguments, \n",
    "    Trainer, \n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel, PeftConfig\n",
    "from bert_score import score\n",
    "import onnxruntime as ort\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bert_score import score as bert_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef634522-7782-488e-b7db-9087277cbc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99102de2-dcbf-4073-acfd-7bfc824d4508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2389032fd44bdf86b8a5837443c6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/646 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891c3a5755ea4c97a71eaf8dbed06f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d04158a85a4d25b7fc65d873dcc663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c54aa4d299452ba20c0a2929e0c408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8750744d258d4d6387a6811c84e7e9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4480de01751b4184a7b66bc84e636675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce83db0a884448ba9c5d3dc89d3c1521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7259a2ba-f3b9-4713-b0f0-fac43d8e294b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32016, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32016, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d01799a-d78c-44f4-8d25-484671ed776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    dtype_size = torch.finfo(model.dtype).bits // 8\n",
    "    \n",
    "    model_size_gb = total_params * dtype_size / (1024 ** 3)\n",
    "    print(f\"Model size: {model_size_gb:2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8390be8-f2f0-44d2-a514-31c9f5646a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 25.103043 GB\n"
     ]
    }
   ],
   "source": [
    "get_model_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ba147-ff75-4ae3-a934-0fed0478d870",
   "metadata": {},
   "source": [
    "### Floating Point 15 params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "121c0545-e9ff-4873-a42e-3bcabf34231f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fc795087b74fd0b2663ea7a6f0932f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"codellama/CodeLlama-7b-Instruct-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    # device_map={\"\": 0},\n",
    "    # low_cpu_mem_usage=True\n",
    "    device_map=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5b9097e-bc5f-482c-b5f6-8ec29b6977e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 12.551521 GB\n"
     ]
    }
   ],
   "source": [
    "get_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77cc5210-f4f3-4842-a142-1a9ddb7f00ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 11 11:42:31 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off |   00000000:27:00.0 Off |                    0 |\n",
      "| N/A   57C    P0             80W /  300W |   14139MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f3cac4-bf69-4588-aca5-a97eb7d4a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/object_group/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90160599-5139-4efe-af50-0e539dfcd398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    {\"comment_id\": 74291026, \"comment_user_login\": \"vikerman\", \"comment_body\": \"Is there a better way to avoid having this in different places?\\n\", \"comment_created_at\": \"2016-08-10T17:30:42+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10620#discussion_r74291026\", \"comment_path\": \"modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"comment_position\": 10, \"comment_original_position\": 10, \"comment_commit_id\": \"ee8e802b7bc25eafbe54109b3924e9dbc36dce11\", \"comment_original_commit_id\": \"ee8e802b7bc25eafbe54109b3924e9dbc36dce11\", \"diff_line_content\": \"}\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 15, \"diff_hunk_header\": \"\", \"diff\": \"@@ -6,10 +6,13 @@\\n  * found in the LICENSE file at https://angular.io/license\\n  */\\n \\n-import {unimplemented} from '../../facade/exceptions';\\n+import {BaseException} from '@angular/core';\\n import {isPresent} from '../../facade/lang';\\n import {AbstractControl} from '../model';\\n \\n+function unimplemented(): any {\\n+  throw new BaseException('unimplemented');\", \"side\": \"RIGHT\", \"line_offset\": 9, \"diff_file_source\": \"a/modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"diff_file_target\": \"b/modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74305223, \"comment_user_login\": \"alexeagle\", \"comment_body\": \"we could export it in the public API but that's not nice.\\nOr we could inline the method and delete it.\\n\", \"comment_created_at\": \"2016-08-10T18:42:59+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10620#discussion_r74305223\", \"comment_path\": \"modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"comment_position\": 10, \"comment_original_position\": 10, \"comment_commit_id\": \"ee8e802b7bc25eafbe54109b3924e9dbc36dce11\", \"comment_original_commit_id\": \"ee8e802b7bc25eafbe54109b3924e9dbc36dce11\", \"diff_line_content\": \"}\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 15, \"diff_hunk_header\": \"\", \"diff\": \"@@ -6,10 +6,13 @@\\n  * found in the LICENSE file at https://angular.io/license\\n  */\\n \\n-import {unimplemented} from '../../facade/exceptions';\\n+import {BaseException} from '@angular/core';\\n import {isPresent} from '../../facade/lang';\\n import {AbstractControl} from '../model';\\n \\n+function unimplemented(): any {\\n+  throw new BaseException('unimplemented');\", \"side\": \"RIGHT\", \"line_offset\": 9, \"diff_file_source\": \"a/modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"diff_file_target\": \"b/modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74523490, \"comment_user_login\": \"vicb\", \"comment_body\": \"const\\n\", \"comment_created_at\": \"2016-08-11T23:43:20+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74523490\", \"comment_path\": \"modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"comment_position\": 36, \"comment_original_position\": 36, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"91f50b2f513f99cf56b7406b3a74066e128b9c7d\", \"diff_line_content\": \"    it('should support i18n for content tags', () => {\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 79, \"diff_hunk_header\": \"describe('template codegen output', () => {\", \"diff\": \"@@ -44,24 +44,40 @@ describe('template codegen output', () => {\\n   it('should support ngIf', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     compFixture.componentInstance.ctxBool = true;\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(3);\\n+    expect(debugElement.children.length).toBe(4);\\n     expect(debugElement.children[2].injector.get(MultipleComponentsMyComp)).toBeTruthy();\\n   });\\n \\n   it('should support ngFor', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     // test NgFor\\n     compFixture.componentInstance.ctxArr = [1, 2];\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(4);\\n+    expect(debugElement.children.length).toBe(5);\\n     expect(debugElement.children[2].attributes['value']).toBe('1');\\n     expect(debugElement.children[3].attributes['value']).toBe('2');\\n   });\\n+\\n+  describe('i18n', () => {\\n+    it('should support i18n for content tags', () => {\\n+      var compFixture = createComponent(BasicComp);\\n+      expect(compFixture.componentInstance.ctxLocale).toEqual('FI');\\n+    });\\n+\\n+    it('should support i18n for content tags', () => {\\n+      var compFixture = createComponent(BasicComp);\", \"side\": \"RIGHT\", \"line_offset\": 35, \"diff_file_source\": \"a/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74523504, \"comment_user_login\": \"vicb\", \"comment_body\": \"const\\n\", \"comment_created_at\": \"2016-08-11T23:43:27+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74523504\", \"comment_path\": \"modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"comment_position\": 31, \"comment_original_position\": 31, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"91f50b2f513f99cf56b7406b3a74066e128b9c7d\", \"diff_line_content\": \"    it('should inject the translations format into the component', () => {\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 74, \"diff_hunk_header\": \"describe('template codegen output', () => {\", \"diff\": \"@@ -44,24 +44,40 @@ describe('template codegen output', () => {\\n   it('should support ngIf', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     compFixture.componentInstance.ctxBool = true;\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(3);\\n+    expect(debugElement.children.length).toBe(4);\\n     expect(debugElement.children[2].injector.get(MultipleComponentsMyComp)).toBeTruthy();\\n   });\\n \\n   it('should support ngFor', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     // test NgFor\\n     compFixture.componentInstance.ctxArr = [1, 2];\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(4);\\n+    expect(debugElement.children.length).toBe(5);\\n     expect(debugElement.children[2].attributes['value']).toBe('1');\\n     expect(debugElement.children[3].attributes['value']).toBe('2');\\n   });\\n+\\n+  describe('i18n', () => {\\n+    it('should support i18n for content tags', () => {\\n+      var compFixture = createComponent(BasicComp);\", \"side\": \"RIGHT\", \"line_offset\": 30, \"diff_file_source\": \"a/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74526501, \"comment_user_login\": \"vicb\", \"comment_body\": \"fi\\n\", \"comment_created_at\": \"2016-08-12T00:18:35+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74526501\", \"comment_path\": \"modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"comment_position\": 32, \"comment_original_position\": 32, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"7333b4c6d9527a1a6b812ab6eea2797f228d03bd\", \"diff_line_content\": \"      const compFixture = createComponent(BasicComp);\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 75, \"diff_hunk_header\": \"describe('template codegen output', () => {\", \"diff\": \"@@ -44,24 +44,45 @@ describe('template codegen output', () => {\\n   it('should support ngIf', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     compFixture.componentInstance.ctxBool = true;\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(3);\\n+    expect(debugElement.children.length).toBe(4);\\n     expect(debugElement.children[2].injector.get(MultipleComponentsMyComp)).toBeTruthy();\\n   });\\n \\n   it('should support ngFor', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     // test NgFor\\n     compFixture.componentInstance.ctxArr = [1, 2];\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(4);\\n+    expect(debugElement.children.length).toBe(5);\\n     expect(debugElement.children[2].attributes['value']).toBe('1');\\n     expect(debugElement.children[3].attributes['value']).toBe('2');\\n   });\\n+\\n+  describe('i18n', () => {\\n+    it('should inject the locale into the component', () => {\\n+      const compFixture = createComponent(BasicComp);\\n+      expect(compFixture.componentInstance.ctxLocale).toEqual('FI');\", \"side\": \"RIGHT\", \"line_offset\": 31, \"diff_file_source\": \"a/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74526531, \"comment_user_login\": \"vicb\", \"comment_body\": \"remove !\\n\", \"comment_created_at\": \"2016-08-12T00:19:06+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74526531\", \"comment_path\": \"modules/@angular/compiler-cli/src/codegen.ts\", \"comment_position\": 36, \"comment_original_position\": 36, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"7333b4c6d9527a1a6b812ab6eea2797f228d03bd\", \"diff_line_content\": \"    const reflectorHost = new ReflectorHost(program, compilerHost, options, reflectorHostContext);\\n\", \"diff_line_type\": \"context\", \"diff_line_source_no\": 132, \"diff_line_target_no\": 142, \"diff_hunk_header\": \"export class CodeGenerator {\", \"diff\": \"@@ -88,6 +93,35 @@ export class CodeGenerator {\\n     return path.join(this.options.genDir, relativePath);\\n   }\\n \\n+  private _constructTranslationBundle(fileMetas: any[], analyzedNgModules: any): Promise<any> {\", \"side\": \"RIGHT\", \"line_offset\": 11, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/codegen.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/codegen.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74526731, \"comment_user_login\": \"vicb\", \"comment_body\": \"append at the end to make diff readable\\n\", \"comment_created_at\": \"2016-08-12T00:21:49+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74526731\", \"comment_path\": \"modules/@angular/compiler-cli/src/codegen.ts\", \"comment_position\": 26, \"comment_original_position\": 26, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"7333b4c6d9527a1a6b812ab6eea2797f228d03bd\", \"diff_line_content\": \"      }\\n\", \"diff_line_type\": \"context\", \"diff_line_source_no\": 129, \"diff_line_target_no\": 132, \"diff_hunk_header\": \"export class CodeGenerator {\", \"diff\": \"@@ -32,7 +35,9 @@ const PREAMBLE = `/**\\n \\n export class CodeGenerator {\\n   constructor(\\n-      private options: AngularCompilerOptions, private program: ts.Program,\\n+      private options: AngularCompilerOptions, private transContent: string,\", \"side\": \"RIGHT\", \"line_offset\": 1, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/codegen.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/codegen.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74527376, \"comment_user_login\": \"vicb\", \"comment_body\": \"This is the only line that you should keep beside loading the file\\n\", \"comment_created_at\": \"2016-08-12T00:30:39+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74527376\", \"comment_path\": \"modules/@angular/compiler-cli/src/codegen.ts\", \"comment_position\": 46, \"comment_original_position\": 130, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"7333b4c6d9527a1a6b812ab6eea2797f228d03bd\", \"diff_line_content\": \"        new NgModuleCompiler(), new TypeScriptEmitter(reflectorHost), cliOptions.locale,\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 164, \"diff_hunk_header\": \"export class CodeGenerator {\", \"diff\": \"@@ -132,7 +175,7 @@ export class CodeGenerator {\\n     const reflectorHost = new ReflectorHost(program, compilerHost, options, reflectorHostContext);\\n     const staticReflector = new StaticReflector(reflectorHost);\\n     StaticAndDynamicReflectionCapabilities.install(staticReflector);\\n-    const htmlParser = new compiler.i18n.HtmlParser(new HtmlParser());\\n+    const htmlParser = new compiler.i18n.HtmlParser(new HtmlParser(), transContent);\", \"side\": \"RIGHT\", \"line_offset\": 3, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/codegen.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/codegen.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74528827, \"comment_user_login\": \"vicb\", \"comment_body\": \"Id\\n\", \"comment_created_at\": \"2016-08-12T00:51:47+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74528827\", \"comment_path\": \"modules/@angular/compiler-cli/integrationtest/src/basic.ts\", \"comment_position\": 15, \"comment_original_position\": 15, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"e7940fc0e83c9d0a549891774db0a609ec591c19\", \"diff_line_content\": \"  }\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 30, \"diff_hunk_header\": \"export class BasicComp {\", \"diff\": \"@@ -23,5 +23,9 @@ export class BasicComp {\\n   ctxProp: string;\\n   ctxBool: boolean;\\n   ctxArr: any[] = [];\\n-  constructor() { this.ctxProp = 'initialValue'; }\\n+  constructor(\\n+      @Inject(LOCALE_ID) public localeID: string,\", \"side\": \"RIGHT\", \"line_offset\": 7, \"diff_file_source\": \"a/modules/@angular/compiler-cli/integrationtest/src/basic.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/integrationtest/src/basic.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74528853, \"comment_user_login\": \"vicb\", \"comment_body\": \"only add the format\\n\", \"comment_created_at\": \"2016-08-12T00:52:10+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74528853\", \"comment_path\": \"modules/@angular/compiler-cli/src/extract_i18n.ts\", \"comment_position\": 6, \"comment_original_position\": 6, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"e7940fc0e83c9d0a549891774db0a609ec591c19\", \"diff_line_content\": \"  const extractor = Extractor.create(ngOptions, cliOptions.i18nFormat, program, host);\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 33, \"diff_hunk_header\": \"import {StaticAndDynamicReflectionCapabilities} from './static_reflection_capabi\", \"diff\": \"@@ -28,8 +28,9 @@ import {StaticAndDynamicReflectionCapabilities} from './static_reflection_capabi\\n import {StaticReflector, StaticSymbol} from './static_reflector';\\n \\n function extract(\\n-    ngOptions: tsc.AngularCompilerOptions, program: ts.Program, host: ts.CompilerHost) {\\n-  const extractor = Extractor.create(ngOptions, program, host);\\n+    ngOptions: tsc.AngularCompilerOptions, cliOptions: tsc.CliOptions, program: ts.Program,\", \"side\": \"RIGHT\", \"line_offset\": 5, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/extract_i18n.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/extract_i18n.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74530724, \"comment_user_login\": \"vicb\", \"comment_body\": \"`, null, null` would be more semantically correct\\n\", \"comment_created_at\": \"2016-08-12T01:22:30+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74530724\", \"comment_path\": \"modules/@angular/compiler-cli/src/extract_i18n.ts\", \"comment_position\": 37, \"comment_original_position\": 37, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"6781377043d6eae20d6504b83a121ebde353f043\", \"diff_line_content\": \"}\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 196, \"diff_hunk_header\": \"interface FileMetadata {\", \"diff\": \"@@ -163,7 +164,7 @@ export class Extractor {\\n         config, console, elementSchemaRegistry, staticReflector);\\n     const offlineCompiler = new compiler.OfflineCompiler(\\n         resolver, normalizer, tmplParser, new StyleCompiler(urlResolver), new ViewCompiler(config),\\n-        new NgModuleCompiler(), new TypeScriptEmitter(reflectorHost));\\n+        new NgModuleCompiler(), new TypeScriptEmitter(reflectorHost), '', translationsFormat);\", \"side\": \"RIGHT\", \"line_offset\": 12, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/extract_i18n.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/extract_i18n.ts\", \"repo\": \"angular/angular\"}\n"
     ]
    }
   ],
   "source": [
    "train = \"/mnt/object_group/data/processed/train.jsonl.gz\"\n",
    "with gzip.open(train, 'rt', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(\"    \" + line.strip())\n",
    "        if i >= 10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86df7928-62f7-4ac6-8f93-e08ce6a4b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/mnt/object_group/data/processed\")  # Adjust as needed\n",
    "\n",
    "def load_samples(limit_per_split=10):\n",
    "    diff_samples = []\n",
    "    for repo_dir in DATA_ROOT.iterdir():\n",
    "        if not repo_dir.is_dir():\n",
    "            continue\n",
    "        for pr_dir in (repo_dir / \"diff\").iterdir():\n",
    "            pr_id = pr_dir.name\n",
    "            diff_file = pr_dir\n",
    "            comments_file = DATA_ROOT / repo_dir.name / \"comments\" / f\"{repo_dir.name}_{pr_id}_comments.jsonl\"\n",
    "\n",
    "            if not diff_file.exists() or not comments_file.exists():\n",
    "                continue\n",
    "\n",
    "            with open(diff_file, \"r\", encoding=\"utf-8\") as df:\n",
    "                diff_content = df.read()\n",
    "\n",
    "            with open(comments_file, \"r\", encoding=\"utf-8\") as cf:\n",
    "                for line in cf:\n",
    "                    try:\n",
    "                        comment = json.loads(line)\n",
    "                        offset = comment.get(\"original_position\")\n",
    "                        side = comment.get(\"side\", \"RIGHT\")\n",
    "                        body = comment.get(\"body\", \"\").strip()\n",
    "                        if offset is not None and body:\n",
    "                            sample = {\n",
    "                                \"input\": f\"<DIFF>\\n{diff_content}\\n</DIFF>\\n<COMMENT side=\\\"{side}\\\" offset=\\\"{offset}\\\">\",\n",
    "                                \"output\": body\n",
    "                            }\n",
    "                            diff_samples.append(sample)\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "\n",
    "    random.shuffle(diff_samples)\n",
    "    return {\n",
    "        \"train\": diff_samples[:limit_per_split],\n",
    "        \"test\": diff_samples[limit_per_split:2*limit_per_split],\n",
    "        \"eval\": diff_samples[2*limit_per_split:3*limit_per_split],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c70b5a55-a831-4432-ae15-5b910735780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_gz(file_path, limit):\n",
    "    samples = []\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= limit:\n",
    "                break\n",
    "            entry = json.loads(line)\n",
    "            prompt = f\"<DIFF>\\n{entry['diff']}\\n</DIFF>\\n\"\n",
    "            comment = f\"<COMMENT side=\\\"{entry['side']}\\\" offset=\\\"{entry['line_offset']}\\\">{entry['comment_body']}\"\n",
    "            samples.append({'input': prompt, 'label': comment})\n",
    "    return samples\n",
    "\n",
    "train_data = load_jsonl_gz(\"/mnt/object_group/data/processed/train.jsonl.gz\", 10)\n",
    "test_data  = load_jsonl_gz(\"/mnt/object_group/data/processed/test.jsonl.gz\", 8)\n",
    "eval_data  = load_jsonl_gz(\"/mnt/object_group/data/processed/val.jsonl.gz\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0fb7e8b-f409-4557-b4e6-61fafc226c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input', 'label'])\n",
      "<DIFF>\n",
      "@@ -6,10 +6,13 @@\n",
      "  * found in the LICENSE file at https://angular.io/license\n",
      "  */\n",
      " \n",
      "-import {unimplemented} from '../../facade/exceptions';\n",
      "+import {BaseException} from '@angular/core';\n",
      " import {isPresent} from '../../facade/lang';\n",
      " import {AbstractControl} from '../model';\n",
      " \n",
      "+function unimplemented(): any {\n",
      "+  throw new BaseException('unimplemented');\n",
      "</DIFF>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"9\">Is there a better way to avoid having this in different places?\n",
      "\n",
      "<DIFF>\n",
      "@@ -6,10 +6,13 @@\n",
      "  * found in the LICENSE file at https://angular.io/license\n",
      "  */\n",
      " \n",
      "-import {unimplemented} from '../../facade/exceptions';\n",
      "+import {BaseException} from '@angular/core';\n",
      " import {isPresent} from '../../facade/lang';\n",
      " import {AbstractControl} from '../model';\n",
      " \n",
      "+function unimplemented(): any {\n",
      "+  throw new BaseException('unimplemented');\n",
      "</DIFF>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"9\">we could export it in the public API but that's not nice.\n",
      "Or we could inline the method and delete it.\n",
      "\n",
      "<DIFF>\n",
      "@@ -44,24 +44,40 @@ describe('template codegen output', () => {\n",
      "   it('should support ngIf', () => {\n",
      "     var compFixture = createComponent(BasicComp);\n",
      "     var debugElement = compFixture.debugElement;\n",
      "-    expect(debugElement.children.length).toBe(2);\n",
      "+    expect(debugElement.children.length).toBe(3);\n",
      " \n",
      "     compFixture.componentInstance.ctxBool = true;\n",
      "     compFixture.detectChanges();\n",
      "-    expect(debugElement.children.length).toBe(3);\n",
      "+    expect(debugElement.children.length).toBe(4);\n",
      "     expect(debugElement.children[2].injector.get(MultipleComponentsMyComp)).toBeTruthy();\n",
      "   });\n",
      " \n",
      "   it('should support ngFor', () => {\n",
      "     var compFixture = createComponent(BasicComp);\n",
      "     var debugElement = compFixture.debugElement;\n",
      "-    expect(debugElement.children.length).toBe(2);\n",
      "+    expect(debugElement.children.length).toBe(3);\n",
      " \n",
      "     // test NgFor\n",
      "     compFixture.componentInstance.ctxArr = [1, 2];\n",
      "     compFixture.detectChanges();\n",
      "-    expect(debugElement.children.length).toBe(4);\n",
      "+    expect(debugElement.children.length).toBe(5);\n",
      "     expect(debugElement.children[2].attributes['value']).toBe('1');\n",
      "     expect(debugElement.children[3].attributes['value']).toBe('2');\n",
      "   });\n",
      "+\n",
      "+  describe('i18n', () => {\n",
      "+    it('should support i18n for content tags', () => {\n",
      "+      var compFixture = createComponent(BasicComp);\n",
      "+      expect(compFixture.componentInstance.ctxLocale).toEqual('FI');\n",
      "+    });\n",
      "+\n",
      "+    it('should support i18n for content tags', () => {\n",
      "+      var compFixture = createComponent(BasicComp);\n",
      "</DIFF>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"35\">const\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].keys())\n",
    "\n",
    "for i in range(3):\n",
    "    print(train_data[i][\"input\"])\n",
    "    print(train_data[i][\"label\"])\n",
    "# print(train_data[0][\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4009389d-1604-4d45-8b29-356c1eb50ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "instruction = (\n",
    "    \"You are a helpful code reviewer. \"\n",
    "    \"Given a code diff, generate all relevant review comments. \"\n",
    "    \"Each comment must be in the format: \"\n",
    "    \"<COMMENT side=\\\"RIGHT\\\" offset=\\\"X\\\">Your comment here.\\n\"\n",
    "    \"Only output comments, nothing else.\\n\\n\"\n",
    "    \"### Code Diff:\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eb6f797-96f7-44ad-b438-ed3c12e850ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(text):\n",
    "    pattern = re.compile(r'<COMMENT side=\"(?P<side>[^\"]+)\" offset=\"(?P<offset>\\d+)\">(?P<comment>.+)')\n",
    "    results = []\n",
    "    for line in text.strip().splitlines():\n",
    "        match = pattern.match(line.strip())\n",
    "        if match:\n",
    "            results.append({\n",
    "                \"side\": match.group(\"side\"),\n",
    "                \"offset\": int(match.group(\"offset\")),\n",
    "                \"comment\": match.group(\"comment\").strip()\n",
    "            })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bad0089a-5b53-4620-9ee6-2cb46efef9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32016, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32016, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec15c265-2cbe-4477-b5d4-5661257c702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_match(pred_comments, true_comments, window=3):\n",
    "    correct = 0\n",
    "    total = len(pred_comments)\n",
    "\n",
    "    gt_pairs = {(c[\"side\"], c[\"offset\"]) for c in true_comments}\n",
    "    matched = set()\n",
    "\n",
    "    for pred in pred_comments:\n",
    "        pred_side, pred_offset = pred[\"side\"], pred[\"offset\"]\n",
    "        for gt in gt_pairs:\n",
    "            gt_side, gt_offset = gt\n",
    "            if pred_side == gt_side and abs(pred_offset - gt_offset) <= window:\n",
    "                matched.add(gt)\n",
    "                correct += 1\n",
    "                break  # count each pred only once\n",
    "\n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e72a6268-8a4e-4601-ae46-37fea7b358fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 0 ===\n",
      "[INST] You are a helpful code reviewer. Given a code diff, generate all relevant review comments. Each comment must be in the format: <COMMENT side=\"RIGHT\" offset=\"X\">Your comment here.\n",
      "Only output comments, nothing else.\n",
      "\n",
      "### Code Diff:\n",
      "<DIFF>\n",
      "@@ -838,45 +839,58 @@ function performConcurrentWorkOnRoot(root, didTimeout) {\n",
      "       throw fatalError;\n",
      "     }\n",
      " \n",
      "-    // Check if this render may have yielded to a concurrent event, and if so,\n",
      "-    // confirm that any newly rendered stores are consistent.\n",
      "-    // TODO: It's possible that even a concurrent render may never have yielded\n",
      "-    // to the main thread, if it was fast enough, or if it expired. We could\n",
      "-    // skip the consistency check in that case, too.\n",
      "-    const renderWasConcurrent = !includesBlockingLane(root, lanes);\n",
      "-    const finishedWork: Fiber = (root.current.alternate: any);\n",
      "-    if (\n",
      "-      renderWasConcurrent &&\n",
      "-      !isRenderConsistentWithExternalStores(finishedWork)\n",
      "-    ) {\n",
      "-      // A store was mutated in an interleaved event. Render again,\n",
      "-      // synchronously, to block further mutations.\n",
      "-      exitStatus = renderRootSync(root, lanes);\n",
      "-\n",
      "-      // We need to check again if something threw\n",
      "-      if (exitStatus === RootErrored) {\n",
      "-        const errorRetryLanes = getLanesToRetrySynchronouslyOnError(root);\n",
      "-        if (errorRetryLanes !== NoLanes) {\n",
      "-          lanes = errorRetryLanes;\n",
      "-          exitStatus = recoverFromConcurrentError(root, errorRetryLanes);\n",
      "-          // We assume the tree is now consistent because we didn't yield to any\n",
      "-          // concurrent events.\n",
      "+    if (exitStatus === RootDidNotComplete) {\n",
      "</DIFF> [/INST]  <COMMENT side=\"RIGHT\" offset=\"838\">This code looks like it's checking if a render was concurrent and if it was consistent with external stores. It's also checking if the render was interrupted by an error and if so, it's retrying the render synchronously.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"840\">It's possible that even a concurrent render may never have yielded to the main thread, if it was fast enough, or if it expired. We could skip the consistency check in that case, too.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"842\">The code is checking if the render was concurrent and if it was consistent with external stores. If it was not consistent, it's retrying the render synchronously.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"844\">It's assuming that the tree is now consistent because it didn't yield to any concurrent events.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"846\">It's checking if the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 1 ===\n",
      "[INST] You are a helpful code reviewer. Given a code diff, generate all relevant review comments. Each comment must be in the format: <COMMENT side=\"RIGHT\" offset=\"X\">Your comment here.\n",
      "Only output comments, nothing else.\n",
      "\n",
      "### Code Diff:\n",
      "<DIFF>\n",
      "@@ -838,45 +839,58 @@ function performConcurrentWorkOnRoot(root, didTimeout) {\n",
      "       throw fatalError;\n",
      "     }\n",
      " \n",
      "-    // Check if this render may have yielded to a concurrent event, and if so,\n",
      "-    // confirm that any newly rendered stores are consistent.\n",
      "-    // TODO: It's possible that even a concurrent render may never have yielded\n",
      "-    // to the main thread, if it was fast enough, or if it expired. We could\n",
      "-    // skip the consistency check in that case, too.\n",
      "-    const renderWasConcurrent = !includesBlockingLane(root, lanes);\n",
      "-    const finishedWork: Fiber = (root.current.alternate: any);\n",
      "-    if (\n",
      "-      renderWasConcurrent &&\n",
      "-      !isRenderConsistentWithExternalStores(finishedWork)\n",
      "-    ) {\n",
      "-      // A store was mutated in an interleaved event. Render again,\n",
      "-      // synchronously, to block further mutations.\n",
      "-      exitStatus = renderRootSync(root, lanes);\n",
      "-\n",
      "-      // We need to check again if something threw\n",
      "-      if (exitStatus === RootErrored) {\n",
      "-        const errorRetryLanes = getLanesToRetrySynchronouslyOnError(root);\n",
      "-        if (errorRetryLanes !== NoLanes) {\n",
      "-          lanes = errorRetryLanes;\n",
      "-          exitStatus = recoverFromConcurrentError(root, errorRetryLanes);\n",
      "-          // We assume the tree is now consistent because we didn't yield to any\n",
      "-          // concurrent events.\n",
      "+    if (exitStatus === RootDidNotComplete) {\n",
      "+      // The render unwound without completing the tree. This happens in special\n",
      "+      // cases where need to exit the current render without producing a\n",
      "+      // consistent tree or committing.\n",
      "+      //\n",
      "+      // This should only happen during a concurrent render, not a discrete or\n",
      "+      // synchronous update. We should have already checked for this when we\n",
      "+      // unwound the stack.\n",
      "</DIFF> [/INST]  <COMMENT side=\"RIGHT\" offset=\"838\">This code looks like it's checking if a render was concurrent and if it was consistent with external stores. However, it's not clear why this check is necessary or what the implications of this check are.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"845\">This code is checking if a render was concurrent and if it was consistent with external stores. If the render was concurrent and the stores were not consistent, it will re-render the tree synchronously to block further mutations.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"853\">This code is checking if a render was concurrent and if it was consistent with external stores. If the render was concurrent and the stores were not consistent, it will re-render the tree synchronously to block further mutations. However, it's not clear why this check is necessary or what the implications of this check are.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"861\">This code is checking if a render was concurrent and if it was consistent with external stores. If the render\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 2 ===\n",
      "[INST] You are a helpful code reviewer. Given a code diff, generate all relevant review comments. Each comment must be in the format: <COMMENT side=\"RIGHT\" offset=\"X\">Your comment here.\n",
      "Only output comments, nothing else.\n",
      "\n",
      "### Code Diff:\n",
      "<DIFF>\n",
      "@@ -1149,6 +1163,10 @@ function performSyncWorkOnRoot(root) {\n",
      "     throw fatalError;\n",
      "   }\n",
      " \n",
      "+  if (exitStatus === RootDidNotComplete) {\n",
      "</DIFF> [/INST]  <COMMENT side=\"RIGHT\" offset=\"1150\">This line is not needed. The `throw` statement will already cause the function to exit with an error. It's not necessary to check the `exitStatus` variable and throw a new error if it's not `RootCompleted`.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"1164\">This line is not needed. The `if` statement is already checking if the `exitStatus` variable is equal to `RootDidNotComplete`. It's not necessary to check the `exitStatus` variable again in the `if` statement's body.</COMMENT>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 3 ===\n",
      "[INST] You are a helpful code reviewer. Given a code diff, generate all relevant review comments. Each comment must be in the format: <COMMENT side=\"RIGHT\" offset=\"X\">Your comment here.\n",
      "Only output comments, nothing else.\n",
      "\n",
      "### Code Diff:\n",
      "<DIFF>\n",
      "@@ -739,14 +739,20 @@ describe('ReactCache', () => {\n",
      "     await act(async () => {\n",
      "       refresh();\n",
      "     });\n",
      "-    expect(Scheduler).toHaveYielded(['Cache miss! [A]', 'Loading...']);\n",
      "+    expect(Scheduler).toHaveYielded([\n",
      "+      'Cache miss! [A]',\n",
      "+      'Loading...',\n",
      "+      // TODO: This happens too early, because we don't retain the refreshed\n",
      "+      // cache until it commits. Will fix in next step.\n",
      "+      'Cache cleanup: A [v1]',\n",
      "</DIFF> [/INST]  <COMMENT side=\"RIGHT\" offset=\"10\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"15\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"18\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"21\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"24\">This comment is suggesting that the cache cleanup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 4 ===\n",
      "[INST] You are a helpful code reviewer. Given a code diff, generate all relevant review comments. Each comment must be in the format: <COMMENT side=\"RIGHT\" offset=\"X\">Your comment here.\n",
      "Only output comments, nothing else.\n",
      "\n",
      "### Code Diff:\n",
      "<DIFF>\n",
      "@@ -739,14 +739,20 @@ describe('ReactCache', () => {\n",
      "     await act(async () => {\n",
      "       refresh();\n",
      "     });\n",
      "-    expect(Scheduler).toHaveYielded(['Cache miss! [A]', 'Loading...']);\n",
      "+    expect(Scheduler).toHaveYielded([\n",
      "+      'Cache miss! [A]',\n",
      "+      'Loading...',\n",
      "+      // TODO: This happens too early, because we don't retain the refreshed\n",
      "+      // cache until it commits. Will fix in next step.\n",
      "+      'Cache cleanup: A [v1]',\n",
      "</DIFF> [/INST]  <COMMENT side=\"RIGHT\" offset=\"10\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"15\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"18\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"21\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"24\">This comment is suggesting that the cache cleanup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 5 ===\n",
      "[INST] You are a helpful code reviewer. Given a code diff, generate all relevant review comments. Each comment must be in the format: <COMMENT side=\"RIGHT\" offset=\"X\">Your comment here.\n",
      "Only output comments, nothing else.\n",
      "\n",
      "### Code Diff:\n",
      "<DIFF>\n",
      "@@ -739,14 +739,20 @@ describe('ReactCache', () => {\n",
      "     await act(async () => {\n",
      "       refresh();\n",
      "     });\n",
      "-    expect(Scheduler).toHaveYielded(['Cache miss! [A]', 'Loading...']);\n",
      "+    expect(Scheduler).toHaveYielded([\n",
      "+      'Cache miss! [A]',\n",
      "+      'Loading...',\n",
      "+      // TODO: This happens too early, because we don't retain the refreshed\n",
      "+      // cache until it commits. Will fix in next step.\n",
      "+      'Cache cleanup: A [v1]',\n",
      "</DIFF> [/INST]  <COMMENT side=\"RIGHT\" offset=\"10\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"15\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"18\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"21\">This comment is suggesting that the cache cleanup is happening too early, before the refreshed cache has committed. This could be fixed by waiting for the cache to commit before cleaning up.</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"24\">This comment is suggesting that the cache cleanup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 6 ===\n",
      "[INST] You are a helpful code reviewer. Given a code diff, generate all relevant review comments. Each comment must be in the format: <COMMENT side=\"RIGHT\" offset=\"X\">Your comment here.\n",
      "Only output comments, nothing else.\n",
      "\n",
      "### Code Diff:\n",
      "<DIFF>\n",
      "@@ -0,0 +1,197 @@\n",
      "+/**\n",
      "+ * Copyright (c) Facebook, Inc. and its affiliates.\n",
      "+ *\n",
      "+ * This source code is licensed under the MIT license found in the\n",
      "+ * LICENSE file in the root directory of this source tree.\n",
      "+ *\n",
      "+ * @emails react-core\n",
      "+ */\n",
      "+\n",
      "+let JSDOM;\n",
      "+let React;\n",
      "+let ReactDOM;\n",
      "+let Scheduler;\n",
      "+let clientAct;\n",
      "+let ReactDOMFizzServer;\n",
      "+let Stream;\n",
      "+let document;\n",
      "+let writable;\n",
      "+let container;\n",
      "+let buffer = '';\n",
      "+let hasErrored = false;\n",
      "+let fatalError = undefined;\n",
      "+let textCache;\n",
      "+\n",
      "+describe('useId', () => {\n",
      "+  beforeEach(() => {\n",
      "+    jest.resetModules();\n",
      "+    JSDOM = require('jsdom').JSDOM;\n",
      "+    React = require('react');\n",
      "+    ReactDOM = require('react-dom');\n",
      "+    Scheduler = require('scheduler');\n",
      "+    clientAct = require('jest-react').act;\n",
      "+    ReactDOMFizzServer = require('react-dom/server');\n",
      "+    Stream = require('stream');\n",
      "+\n",
      "+    textCache = new Map();\n",
      "+\n",
      "+    // Test Environment\n",
      "+    const jsdom = new JSDOM(\n",
      "+      '<!DOCTYPE html><html><head></head><body><div id=\"container\">',\n",
      "+      {\n",
      "+        runScripts: 'dangerously',\n",
      "</DIFF> [/INST]  <COMMENT side=\"RIGHT\" offset=\"1\">This code looks like it's setting up a test environment for a React component. It's using JSDOM to create a virtual DOM, and it's requiring several other libraries that are used in React.</COMMENT>\n",
      "\n",
      "  <COMMENT side=\"RIGHT\" offset=\"10\">The `textCache` variable is being initialized as a new Map, which is a data structure that maps keys to values. It's not clear what this variable is used for, but it's likely that it's being used to cache some data or results.</COMMENT>\n",
      "\n",
      "  <COMMENT side=\"RIGHT\" offset=\"15\">The `describe` function is being used to define a test suite. It's not clear what this test suite is testing, but it's likely that it's testing some functionality related to the `useId` hook.</COMMENT>\n",
      "\n",
      "  <COMMENT side=\"RIGHT\" offset=\"20\">The `beforeEach` function is being used to set up some variables that are used in the test suite. It's not clear what these variables are used for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8/8 [00:58<00:00,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 7 ===\n",
      "[INST] You are a helpful code reviewer. Given a code diff, generate all relevant review comments. Each comment must be in the format: <COMMENT side=\"RIGHT\" offset=\"X\">Your comment here.\n",
      "Only output comments, nothing else.\n",
      "\n",
      "### Code Diff:\n",
      "<DIFF>\n",
      "@@ -389,17 +389,6 @@ describe('ReactSuspense', () => {\n",
      "     expect(root).toMatchRenderedOutput('Hi');\n",
      "   });\n",
      " \n",
      "-  it('throws if tree suspends and none of the Suspense ancestors have a boundary', () => {\n",
      "</DIFF> [/INST]  <COMMENT side=\"RIGHT\" offset=\"389\">This test seems to be testing the behavior of the `ReactSuspense` component when it is used in a situation where it is not expected to be used. The test is checking that an error is thrown when the component suspends and none of the Suspense ancestors have a boundary. However, this test is not actually testing the behavior of the `ReactSuspense` component in this situation. It would be more useful to test the behavior of the component in a real-world scenario where it is actually used.\n",
      "\n",
      "Additionally, the test is not actually testing the error message that is thrown when the component suspends and none of the Suspense ancestors have a boundary. It would be more useful to test that the correct error message is thrown in this situation.\n",
      "\n",
      "Overall, this test seems to be testing the behavior of the `ReactSuspense` component in a way that is not actually relevant to its intended use case. It would be more useful to test the component in a more realistic scenario.\n",
      "</COMMENT>\n",
      "\n",
      "<COMMENT side=\"RIGHT\" offset=\"390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "references = []\n",
    "candidates = []\n",
    "offset_match_total = 0\n",
    "offset_match_correct = 0\n",
    "\n",
    "for i, sample in enumerate(tqdm(test_data[:100])):  # Full test set if needed\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": instruction + sample[\"input\"]}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=4096\n",
    "    ).to(\"cuda:0\")\n",
    "\n",
    "    true_comments = extract_comments(sample[\"label\"])\n",
    "\n",
    "    # Measure inference latency\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=256, do_sample=False)\n",
    "        latencies.append(time.time() - start)\n",
    "\n",
    "    # Decode and evaluate\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
    "    generated_text = generated_text.split(\"Setting `pad_token_id\")[0].strip()\n",
    "    print(f\"\\n=== Sample {i} ===\\n{generated_text}\")\n",
    "\n",
    "    pred_comments = extract_comments(generated_text)\n",
    "\n",
    "    for gt in true_comments:\n",
    "        references.append(gt[\"comment\"])\n",
    "        best_pred = max(pred_comments, key=lambda p: p[\"comment\"], default={\"comment\": \"\"})\n",
    "        candidates.append(best_pred[\"comment\"] if best_pred else \"\")\n",
    "\n",
    "    correct, total = offset_match(pred_comments, true_comments, window=3)\n",
    "    offset_match_correct += correct\n",
    "    offset_match_total += total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49490094-41c4-4d0a-8e51-cb463e34c143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Inference Latency Stats ===\n",
      "Median latency:        7757.82 ms\n",
      "95th percentile:       7990.19 ms\n",
      "99th percentile:       8111.77 ms\n",
      "Throughput (1 sample): 0.13 samples/sec\n"
     ]
    }
   ],
   "source": [
    "# Latency stats\n",
    "print(\"\\n=== Inference Latency Stats ===\")\n",
    "print(f\"Median latency:        {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
    "print(f\"95th percentile:       {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
    "print(f\"99th percentile:       {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
    "print(f\"Throughput (1 sample): {len(latencies) / np.sum(latencies):.2f} samples/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0323dc1-c576-47ab-bbc0-7c930423c226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded12b530986495da51b52e1c454a9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d77327e53a4a4faaefd6e2a83edf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb10eacaf814f9a8e243681bfaff08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba71d0866324ad9b8c8f5c5552e3b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84288e69da2140eab7714604c4bc8e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed8b6878f4641488e94a62857d9a78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe514997ef649c2adbdf3afeaa59fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dc0a4d64694fb1bef9cdaf0324dee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.10 seconds, 83.01 sentences/sec\n",
      "\n",
      "Evaluation Results\n",
      "Avg BERTScore F1: 0.7252\n",
      "Offset Precision: 0/23 = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "# BERTScore\n",
    "P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "print(\"\\nEvaluation Results\")\n",
    "print(f\"Avg BERTScore F1: {F1.mean().item():.4f}\")\n",
    "print(f\"Offset Precision: {offset_match_correct}/{offset_match_total} = {offset_match_correct/offset_match_total:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49350b7-5cf3-458d-84ae-367a972e5511",
   "metadata": {},
   "source": [
    "Batch throughput test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30882c1b-72a9-4340-a50e-fc29d763e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "num_batches = 10\n",
    "batch_inputs = [test_data[i][\"input\"] for i in range(batch_size)]\n",
    "batch_prompts = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": instruction + inp}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    for inp in batch_inputs\n",
    "]\n",
    "\n",
    "encoded = tokenizer(\n",
    "    batch_prompts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=4096\n",
    ").to(\"cuda:0\")\n",
    "\n",
    "# Warm-up\n",
    "with torch.no_grad():\n",
    "    _ = model.generate(**encoded, max_new_tokens=256, do_sample=False)\n",
    "\n",
    "batch_times = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_batches):\n",
    "        start = time.time()\n",
    "        _ = model.generate(**encoded, max_new_tokens=256, do_sample=False)\n",
    "        batch_times.append(time.time() - start)\n",
    "\n",
    "batch_fps = (batch_size * num_batches) / np.sum(batch_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cd99a-3643-4300-8087-f23fbf8940ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Final Evaluation Summary ===\")\n",
    "print(f\"Model Size on Disk:               {model_size_bytes / 1e6:.2f} MB\")\n",
    "print(f\"BERTScore F1 (avg):               {F1.mean().item():.4f}\")\n",
    "print(f\"Location Precision:               {offset_match_correct}/{offset_match_total} = {offset_match_correct / offset_match_total:.4f}\")\n",
    "print(f\"Inference Latency (median):       {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
    "print(f\"Inference Latency (95th pct):     {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
    "print(f\"Inference Latency (99th pct):     {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
    "print(f\"Inference Throughput (1 sample):  {len(latencies) / np.sum(latencies):.2f} samples/sec\")\n",
    "print(f\"Batch Throughput ({batch_size}):  {batch_fps:.2f} samples/sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911505f5-d4bd-4f7b-a8f5-e699dcec3743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6442a9a-f617-463d-a2d5-3aeae7ac6945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
