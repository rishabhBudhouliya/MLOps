{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "755593ec-5202-45ec-a1e9-4bf48536be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip, json, time\n",
    "import torch \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    TrainingArguments, \n",
    "    Trainer, \n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from bert_score import score\n",
    "import onnxruntime as ort\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0874e8ae-b6ed-4294-b7bb-a48615cf3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91a5e99b-69b3-41ca-8372-669999796b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/mnt/object/my_model.pth\"\n",
    "data_path = \"/mnt/object_group/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9752de0a-5d13-4dcd-9004-d5a709a69ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size on Disk: 31415.38 MB\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(model_path) \n",
    "print(f\"Model Size on Disk: {model_size/ (1e6) :.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "13518000-fe32-4aad-b7b9-19173c43f17b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/mnt/object_group/data\n",
      "\n",
      "/mnt/object_group/data/metadata\n",
      "  └── processed_prs.log\n",
      "     --- File preview ---\n",
      "     https://github.com/angular/angular/pull/10609\n",
      "     https://github.com/angular/angular/pull/10616\n",
      "     ---------------------\n",
      "\n",
      "/mnt/object_group/data/processed\n",
      "  └── dataset_card.md\n",
      "     --- File preview ---\n",
      "     # Dataset Card for v1\n",
      "     \n",
      "     ---------------------\n",
      "  └── split_map.yml\n",
      "     --- File preview ---\n",
      "     test:\n",
      "     - facebook_react\n",
      "     ---------------------\n",
      "\n",
      "/mnt/object_group/data/raw\n",
      "\n",
      "/mnt/object_group/data/raw/angular\n",
      "\n",
      "/mnt/object_group/data/raw/angular/angular\n",
      "  └── angular_angular_10609.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/modules/@angular/compiler-cli/package.json b/modules/@angular/compiler-cli/package.json\n",
      "     index 11760c5c75f69..6b06d2ce052af 100644\n",
      "     ---------------------\n",
      "  └── angular_angular_10609_comments.jsonl\n",
      "     --- File preview ---\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/apache\n",
      "\n",
      "/mnt/object_group/data/raw/apache/arrow\n",
      "  └── apache_arrow_41716.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/ci/scripts/cpp_build.sh b/ci/scripts/cpp_build.sh\n",
      "     index a1f40fc360e2f..6a3a53f2533cd 100755\n",
      "     ---------------------\n",
      "  └── apache_arrow_41716_comments.jsonl\n",
      "     --- File preview ---\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/apache/kafka\n",
      "  └── apache_kafka_17527.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/clients/src/main/java/org/apache/kafka/clients/NetworkClientUtils.java b/clients/src/main/java/org/apache/kafka/clients/NetworkClientUtils.java\n",
      "     index e044fd48ee3e1..3e161b1e9939b 100644\n",
      "     ---------------------\n",
      "  └── apache_kafka_17527_comments.jsonl\n",
      "     --- File preview ---\n",
      "     {\"id\": 1805583386, \"user_login\": \"coltmcnealy-lh\", \"body\": \"I noticed when developing my test that repeated calls to `poll()` with `timeoutMs == 10` never resulted in `time.milliseconds()` advancing, so the fictitious `Node` in my test never became ready (time never advanced past the throttled time). That's why I made this change; however, it broke all sorts of things.\", \"path\": \"clients/src/test/java/org/apache/kafka/clients/MockClient.java\", \"position\": 28, \"original_position\": 16, \"commit_id\": \"344a5198f249dee5a1b954f0fe9e5087b4630851\", \"original_commit_id\": \"ec9dd116dd0944fefe4ca4d9c484e7fc60a42730\", \"diff_hunk\": \"@@ -336,6 +336,12 @@ public List<ClientResponse> poll(long timeoutMs, long now) {\\n             copy.add(response);\\n         }\\n \\n+        if (copy.isEmpty()) {\\n+            // Simulate time advancing. If no responses are received, then we know that\\n+            // we waited for the whole timeoutMs.\\n+            time.sleep(timeoutMs);\", \"side\": \"RIGHT\", \"created_at\": \"2024-10-17T23:23:31+00:00\", \"updated_at\": \"2024-10-17T23:23:32+00:00\", \"html_url\": \"https://github.com/apache/kafka/pull/17527#discussion_r1805583386\"}\n",
      "     {\"id\": 1805673698, \"user_login\": \"mjsax\", \"body\": \"I guess most test don't expect that time advanced \\\"automatically\\\"... It think we need to remove this.\\r\\n\\r\\nI think there two possibilities: start a background thread in your test before you call `runOnce()` and let the background thread advance mockTime (maybe too complex?), or, make the `MockTime` object more advanced and add some \\\"auto-time-advance\\\" feature, ie, each time `milliseconds()` is called, advance time by 1ms (or some other value passed into MockTime -- only your test would enable this feature.\", \"path\": \"clients/src/test/java/org/apache/kafka/clients/MockClient.java\", \"position\": 28, \"original_position\": 16, \"commit_id\": \"344a5198f249dee5a1b954f0fe9e5087b4630851\", \"original_commit_id\": \"ec9dd116dd0944fefe4ca4d9c484e7fc60a42730\", \"diff_hunk\": \"@@ -336,6 +336,12 @@ public List<ClientResponse> poll(long timeoutMs, long now) {\\n             copy.add(response);\\n         }\\n \\n+        if (copy.isEmpty()) {\\n+            // Simulate time advancing. If no responses are received, then we know that\\n+            // we waited for the whole timeoutMs.\\n+            time.sleep(timeoutMs);\", \"side\": \"RIGHT\", \"created_at\": \"2024-10-18T00:55:50+00:00\", \"updated_at\": \"2024-10-18T00:55:50+00:00\", \"html_url\": \"https://github.com/apache/kafka/pull/17527#discussion_r1805673698\"}\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/electron\n",
      "\n",
      "/mnt/object_group/data/raw/electron/electron\n",
      "  └── electron_electron_39749.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/spec/api-content-tracing-spec.ts b/spec/api-content-tracing-spec.ts\n",
      "     index 2d43de3e90192..62081ff5d67f3 100644\n",
      "     ---------------------\n",
      "  └── electron_electron_39749_comments.jsonl\n",
      "     --- File preview ---\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/etcd-io\n",
      "\n",
      "/mnt/object_group/data/raw/etcd-io/etcd\n",
      "  └── etcd-io_etcd_16698.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/server/etcdserver/server.go b/server/etcdserver/server.go\n",
      "     index 1d48fa6732c..4b40e32bada 100644\n",
      "     ---------------------\n",
      "  └── etcd-io_etcd_16698_comments.jsonl\n",
      "     --- File preview ---\n",
      "     {\"id\": 1348374074, \"user_login\": \"serathius\", \"body\": \"Did you mean 3 seconds? I'm pretty sure gofail accepts duration which would be more readable.\\r\\n```suggestion\\r\\n\\trequire.NoError(t, clus.Procs[0].Failpoints().Setup(ctx, \\\"beforeApplyEntryNormal\\\", `sleep(3s)`))\\r\\n```\", \"path\": \"tests/e2e/http_health_check_test.go\", \"position\": null, \"original_position\": 187, \"commit_id\": \"1324f032542b61db1d052a541d4d78abe7b0645b\", \"original_commit_id\": \"8c55ebf6e247331dc9e43a1880989a35d58b6870\", \"diff_hunk\": \"@@ -0,0 +1,211 @@\\n+// Copyright 2023 The etcd Authors\\n+//\\n+// Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n+// you may not use this file except in compliance with the License.\\n+// You may obtain a copy of the License at\\n+//\\n+//     http://www.apache.org/licenses/LICENSE-2.0\\n+//\\n+// Unless required by applicable law or agreed to in writing, software\\n+// distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n+// See the License for the specific language governing permissions and\\n+// limitations under the License.\\n+\\n+//go:build !cluster_proxy\\n+\\n+package e2e\\n+\\n+import (\\n+\\t\\\"context\\\"\\n+\\t\\\"io\\\"\\n+\\t\\\"net/http\\\"\\n+\\t\\\"os\\\"\\n+\\t\\\"strings\\\"\\n+\\t\\\"testing\\\"\\n+\\t\\\"time\\\"\\n+\\n+\\t\\\"github.com/stretchr/testify/require\\\"\\n+\\n+\\t\\\"go.etcd.io/etcd/tests/v3/framework/config\\\"\\n+\\t\\\"go.etcd.io/etcd/tests/v3/framework/e2e\\\"\\n+\\t\\\"go.etcd.io/etcd/tests/v3/framework/testutils\\\"\\n+)\\n+\\n+type healthCheckConfig struct {\\n+\\turl                string\\n+\\texpectStatusCode   int\\n+\\texpectTimeoutError bool\\n+}\\n+\\n+func TestHTTPHealthHandler(t *testing.T) {\\n+\\te2e.BeforeTest(t)\\n+\\tclient := &http.Client{}\\n+\\ttcs := []struct {\\n+\\t\\tname           string\\n+\\t\\tinjectFailure  func(ctx context.Context, t *testing.T, clus *e2e.EtcdProcessCluster)\\n+\\t\\tclusterOptions []e2e.EPClusterOption\\n+\\t\\tauthEnabled    bool\\n+\\t\\thealthChecks   []healthCheckConfig\\n+\\t}{\\n+\\t\\t{\\n+\\t\\t\\tname:           \\\"no failures\\\", // happy case\\n+\\t\\t\\tinjectFailure:  noop,\\n+\\t\\t\\tclusterOptions: []e2e.EPClusterOption{e2e.WithClusterSize(1)},\\n+\\t\\t\\thealthChecks: []healthCheckConfig{\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:              \\\"/health\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusOK,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t},\\n+\\t\\t},\\n+\\t\\t{\\n+\\t\\t\\tname:           \\\"activated no space alarm\\\",\\n+\\t\\t\\tinjectFailure:  triggerNoSpaceAlarm,\\n+\\t\\t\\tclusterOptions: []e2e.EPClusterOption{e2e.WithClusterSize(1), e2e.WithQuotaBackendBytes(int64(13 * os.Getpagesize()))},\\n+\\t\\t\\thealthChecks: []healthCheckConfig{\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:              \\\"/health\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusServiceUnavailable,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:              \\\"/health?exclude=NOSPACE\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusOK,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t},\\n+\\t\\t},\\n+\\t\\t{\\n+\\t\\t\\tname:           \\\"overloaded server slow apply\\\",\\n+\\t\\t\\tinjectFailure:  triggerSlowApply,\\n+\\t\\t\\tclusterOptions: []e2e.EPClusterOption{e2e.WithClusterSize(3), e2e.WithGoFailEnabled(true)},\\n+\\t\\t\\thealthChecks: []healthCheckConfig{\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:              \\\"/health?serializable=true\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusOK,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:                \\\"/health?serializable=false\\\",\\n+\\t\\t\\t\\t\\texpectTimeoutError: true,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t},\\n+\\t\\t},\\n+\\t\\t{\\n+\\t\\t\\tname:           \\\"network partitioned\\\",\\n+\\t\\t\\tinjectFailure:  blackhole,\\n+\\t\\t\\tclusterOptions: []e2e.EPClusterOption{e2e.WithClusterSize(3), e2e.WithIsPeerTLS(true), e2e.WithPeerProxy(true)},\\n+\\t\\t\\thealthChecks: []healthCheckConfig{\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:              \\\"/health?serializable=true\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusOK,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:                \\\"/health?serializable=false\\\",\\n+\\t\\t\\t\\t\\texpectTimeoutError: true,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t},\\n+\\t\\t},\\n+\\t\\t{\\n+\\t\\t\\tname:           \\\"raft loop deadlock auth is enabled\\\",\\n+\\t\\t\\tinjectFailure:  triggerRaftLoopDeadLock,\\n+\\t\\t\\tclusterOptions: []e2e.EPClusterOption{e2e.WithClusterSize(3), e2e.WithGoFailEnabled(true)},\\n+\\t\\t\\tauthEnabled:    true,\\n+\\t\\t\\thealthChecks: []healthCheckConfig{\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\t// current kubeadm etcd liveness check failed to detect raft loop deadlock in steady state\\n+\\t\\t\\t\\t\\turl:              \\\"/health?serializable=true\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusOK,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:                \\\"/health?serializable=false\\\",\\n+\\t\\t\\t\\t\\texpectTimeoutError: true,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t},\\n+\\t\\t},\\n+\\t}\\n+\\n+\\tfor _, tc := range tcs {\\n+\\t\\tt.Run(tc.name, func(t *testing.T) {\\n+\\t\\t\\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\\n+\\t\\t\\tdefer cancel()\\n+\\t\\t\\tclus, err := e2e.NewEtcdProcessCluster(ctx, t, tc.clusterOptions...)\\n+\\t\\t\\trequire.NoError(t, err)\\n+\\t\\t\\tdefer clus.Close()\\n+\\t\\t\\ttestutils.ExecuteUntil(ctx, t, func() {\\n+\\t\\t\\t\\tif tc.authEnabled {\\n+\\t\\t\\t\\t\\tsetupAuth(ctx, t, clus.Etcdctl())\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t\\ttc.injectFailure(ctx, t, clus)\\n+\\n+\\t\\t\\t\\tfor _, hc := range tc.healthChecks {\\n+\\t\\t\\t\\t\\trequestURL := clus.Procs[0].EndpointsHTTP()[0] + hc.url\\n+\\t\\t\\t\\t\\tt.Logf(\\\"health check URL is %s\\\", requestURL)\\n+\\t\\t\\t\\t\\tdoHealthCheckAndVerify(t, client, requestURL, hc.expectStatusCode, hc.expectTimeoutError)\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t})\\n+\\t\\t})\\n+\\t}\\n+}\\n+\\n+func doHealthCheckAndVerify(t *testing.T, client *http.Client, url string, expectStatusCode int, expectTimeoutError bool) {\\n+\\tctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)\\n+\\treq, err := http.NewRequestWithContext(ctx, \\\"GET\\\", url, nil)\\n+\\trequire.NoErrorf(t, err, \\\"failed to creat request %+v\\\", err)\\n+\\tresp, herr := client.Do(req)\\n+\\tcancel()\\n+\\tif expectTimeoutError {\\n+\\t\\trequire.Contains(t, herr.Error(), context.DeadlineExceeded.Error())\\n+\\t\\treturn\\n+\\t}\\n+\\trequire.NoErrorf(t, herr, \\\"failed to get response %+v\\\", err)\\n+\\n+\\tbody, err := io.ReadAll(resp.Body)\\n+\\tresp.Body.Close()\\n+\\trequire.NoErrorf(t, err, \\\"failed to read response %+v\\\", err)\\n+\\n+\\tt.Logf(\\\"health check response body is: %s\\\", body)\\n+\\trequire.Equal(t, expectStatusCode, resp.StatusCode)\\n+}\\n+\\n+func noop(_ context.Context, _ *testing.T, _ *e2e.EtcdProcessCluster) {}\\n+\\n+func triggerNoSpaceAlarm(ctx context.Context, t *testing.T, clus *e2e.EtcdProcessCluster) {\\n+\\tbuf := strings.Repeat(\\\"b\\\", os.Getpagesize())\\n+\\tetcdctl := clus.Etcdctl()\\n+\\tfor {\\n+\\t\\tif err := etcdctl.Put(ctx, \\\"foo\\\", buf, config.PutOptions{}); err != nil {\\n+\\t\\t\\tif !strings.Contains(err.Error(), \\\"etcdserver: mvcc: database space exceeded\\\") {\\n+\\t\\t\\t\\tt.Fatal(err)\\n+\\t\\t\\t}\\n+\\t\\t\\tbreak\\n+\\t\\t}\\n+\\t}\\n+}\\n+\\n+func triggerSlowApply(ctx context.Context, t *testing.T, clus *e2e.EtcdProcessCluster) {\\n+\\t// the following proposal will be blocked at applying stage\\n+\\t// because when apply index < committed index, linearizable read would time out.\\n+\\trequire.NoError(t, clus.Procs[0].Failpoints().Setup(ctx, \\\"beforeApplyEntryNormal\\\", `sleep(3000)`))\", \"side\": \"RIGHT\", \"created_at\": \"2023-10-06T07:55:13+00:00\", \"updated_at\": \"2023-10-06T07:55:32+00:00\", \"html_url\": \"https://github.com/etcd-io/etcd/pull/16698#discussion_r1348374074\"}\n",
      "     {\"id\": 1348379362, \"user_login\": \"serathius\", \"body\": \"Love this test!\", \"path\": \"tests/e2e/http_health_check_test.go\", \"position\": 92, \"original_position\": 94, \"commit_id\": \"1324f032542b61db1d052a541d4d78abe7b0645b\", \"original_commit_id\": \"8c55ebf6e247331dc9e43a1880989a35d58b6870\", \"diff_hunk\": \"@@ -0,0 +1,211 @@\\n+// Copyright 2023 The etcd Authors\\n+//\\n+// Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n+// you may not use this file except in compliance with the License.\\n+// You may obtain a copy of the License at\\n+//\\n+//     http://www.apache.org/licenses/LICENSE-2.0\\n+//\\n+// Unless required by applicable law or agreed to in writing, software\\n+// distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n+// See the License for the specific language governing permissions and\\n+// limitations under the License.\\n+\\n+//go:build !cluster_proxy\\n+\\n+package e2e\\n+\\n+import (\\n+\\t\\\"context\\\"\\n+\\t\\\"io\\\"\\n+\\t\\\"net/http\\\"\\n+\\t\\\"os\\\"\\n+\\t\\\"strings\\\"\\n+\\t\\\"testing\\\"\\n+\\t\\\"time\\\"\\n+\\n+\\t\\\"github.com/stretchr/testify/require\\\"\\n+\\n+\\t\\\"go.etcd.io/etcd/tests/v3/framework/config\\\"\\n+\\t\\\"go.etcd.io/etcd/tests/v3/framework/e2e\\\"\\n+\\t\\\"go.etcd.io/etcd/tests/v3/framework/testutils\\\"\\n+)\\n+\\n+type healthCheckConfig struct {\\n+\\turl                string\\n+\\texpectStatusCode   int\\n+\\texpectTimeoutError bool\\n+}\\n+\\n+func TestHTTPHealthHandler(t *testing.T) {\\n+\\te2e.BeforeTest(t)\\n+\\tclient := &http.Client{}\\n+\\ttcs := []struct {\\n+\\t\\tname           string\\n+\\t\\tinjectFailure  func(ctx context.Context, t *testing.T, clus *e2e.EtcdProcessCluster)\\n+\\t\\tclusterOptions []e2e.EPClusterOption\\n+\\t\\tauthEnabled    bool\\n+\\t\\thealthChecks   []healthCheckConfig\\n+\\t}{\\n+\\t\\t{\\n+\\t\\t\\tname:           \\\"no failures\\\", // happy case\\n+\\t\\t\\tinjectFailure:  noop,\\n+\\t\\t\\tclusterOptions: []e2e.EPClusterOption{e2e.WithClusterSize(1)},\\n+\\t\\t\\thealthChecks: []healthCheckConfig{\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:              \\\"/health\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusOK,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t},\\n+\\t\\t},\\n+\\t\\t{\\n+\\t\\t\\tname:           \\\"activated no space alarm\\\",\\n+\\t\\t\\tinjectFailure:  triggerNoSpaceAlarm,\\n+\\t\\t\\tclusterOptions: []e2e.EPClusterOption{e2e.WithClusterSize(1), e2e.WithQuotaBackendBytes(int64(13 * os.Getpagesize()))},\\n+\\t\\t\\thealthChecks: []healthCheckConfig{\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:              \\\"/health\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusServiceUnavailable,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:              \\\"/health?exclude=NOSPACE\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusOK,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t},\\n+\\t\\t},\\n+\\t\\t{\\n+\\t\\t\\tname:           \\\"overloaded server slow apply\\\",\\n+\\t\\t\\tinjectFailure:  triggerSlowApply,\\n+\\t\\t\\tclusterOptions: []e2e.EPClusterOption{e2e.WithClusterSize(3), e2e.WithGoFailEnabled(true)},\\n+\\t\\t\\thealthChecks: []healthCheckConfig{\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:              \\\"/health?serializable=true\\\",\\n+\\t\\t\\t\\t\\texpectStatusCode: http.StatusOK,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t\\t{\\n+\\t\\t\\t\\t\\turl:                \\\"/health?serializable=false\\\",\\n+\\t\\t\\t\\t\\texpectTimeoutError: true,\\n+\\t\\t\\t\\t},\\n+\\t\\t\\t},\\n+\\t\\t},\\n+\\t\\t{\\n+\\t\\t\\tname:           \\\"network partitioned\\\",\\n+\\t\\t\\tinjectFailure:  blackhole,\", \"side\": \"RIGHT\", \"created_at\": \"2023-10-06T08:00:22+00:00\", \"updated_at\": \"2023-10-06T08:00:31+00:00\", \"html_url\": \"https://github.com/etcd-io/etcd/pull/16698#discussion_r1348379362\"}\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/facebook\n",
      "\n",
      "/mnt/object_group/data/raw/facebook/react\n",
      "  └── facebook_react_23267.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/packages/react-reconciler/src/ReactFiberThrow.new.js b/packages/react-reconciler/src/ReactFiberThrow.new.js\n",
      "     index 6a0c70f8e6d00..824f89e967707 100644\n",
      "     ---------------------\n",
      "  └── facebook_react_23267_comments.jsonl\n",
      "     --- File preview ---\n",
      "     {\"id\": 803785355, \"user_login\": \"acdlite\", \"body\": \"This is the key change. Because we exit `throwException` without marking a boundary, the root will unwind all the way to the root without completing.\", \"path\": \"packages/react-reconciler/src/ReactFiberThrow.new.js\", \"position\": 120, \"original_position\": 120, \"commit_id\": \"c14ca1f2373b4347260c520ffd5d11185820b8c6\", \"original_commit_id\": \"c14ca1f2373b4347260c520ffd5d11185820b8c6\", \"diff_hunk\": \"@@ -470,24 +472,47 @@ function throwException(\\n         root,\\n         rootRenderLanes,\\n       );\\n-      attachWakeableListeners(\\n-        suspenseBoundary,\\n-        root,\\n-        wakeable,\\n-        rootRenderLanes,\\n-      );\\n+      // We only attach ping listeners in concurrent mode. Legacy Suspense always\\n+      // commits fallbacks synchronously, so there are no pings.\\n+      if (suspenseBoundary.mode & ConcurrentMode) {\\n+        attachPingListener(root, wakeable, rootRenderLanes);\\n+      }\\n+      attachRetryListener(suspenseBoundary, root, wakeable, rootRenderLanes);\\n       return;\\n     } else {\\n-      // No boundary was found. Fallthrough to error mode.\\n+      // No boundary was found. If we're inside startTransition, this is OK.\\n+      // We can suspend and wait for more data to arrive.\\n+\\n+      if (includesOnlyTransitions(rootRenderLanes)) {\\n+        // This is a transition. Suspend. Since we're not activating a Suspense\\n+        // boundary, this will unwind all the way to the root without performing\\n+        // a second pass to render a fallback. (This is arguably how refresh\\n+        // transitions should work, too, since we're not going to commit the\\n+        // fallbacks anyway.)\\n+        attachPingListener(root, wakeable, rootRenderLanes);\\n+        renderDidSuspendDelayIfPossible();\", \"side\": \"RIGHT\", \"created_at\": \"2022-02-10T15:18:17+00:00\", \"updated_at\": \"2022-02-10T15:18:17+00:00\", \"html_url\": \"https://github.com/facebook/react/pull/23267#discussion_r803785355\"}\n",
      "     {\"id\": 803791975, \"user_login\": \"acdlite\", \"body\": \"This is a new root exit status for when the render phase exits without completing. We treat this like a refresh transition: skip the commit phase and suspend the root so we don't continue working on it.\\r\\n\\r\\nIn the future, I expect we could use this mechanism to unwind from an aborted render without doing a second pass to render fallbacks and error boundaries.\", \"path\": \"packages/react-reconciler/src/ReactFiberWorkLoop.new.js\", \"position\": 62, \"original_position\": 62, \"commit_id\": \"c14ca1f2373b4347260c520ffd5d11185820b8c6\", \"original_commit_id\": \"c14ca1f2373b4347260c520ffd5d11185820b8c6\", \"diff_hunk\": \"@@ -838,45 +839,58 @@ function performConcurrentWorkOnRoot(root, didTimeout) {\\n       throw fatalError;\\n     }\\n \\n-    // Check if this render may have yielded to a concurrent event, and if so,\\n-    // confirm that any newly rendered stores are consistent.\\n-    // TODO: It's possible that even a concurrent render may never have yielded\\n-    // to the main thread, if it was fast enough, or if it expired. We could\\n-    // skip the consistency check in that case, too.\\n-    const renderWasConcurrent = !includesBlockingLane(root, lanes);\\n-    const finishedWork: Fiber = (root.current.alternate: any);\\n-    if (\\n-      renderWasConcurrent &&\\n-      !isRenderConsistentWithExternalStores(finishedWork)\\n-    ) {\\n-      // A store was mutated in an interleaved event. Render again,\\n-      // synchronously, to block further mutations.\\n-      exitStatus = renderRootSync(root, lanes);\\n-\\n-      // We need to check again if something threw\\n-      if (exitStatus === RootErrored) {\\n-        const errorRetryLanes = getLanesToRetrySynchronouslyOnError(root);\\n-        if (errorRetryLanes !== NoLanes) {\\n-          lanes = errorRetryLanes;\\n-          exitStatus = recoverFromConcurrentError(root, errorRetryLanes);\\n-          // We assume the tree is now consistent because we didn't yield to any\\n-          // concurrent events.\\n+    if (exitStatus === RootDidNotComplete) {\", \"side\": \"RIGHT\", \"created_at\": \"2022-02-10T15:24:11+00:00\", \"updated_at\": \"2022-02-10T15:53:36+00:00\", \"html_url\": \"https://github.com/facebook/react/pull/23267#discussion_r803791975\"}\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/grafana\n",
      "\n",
      "/mnt/object_group/data/raw/grafana/grafana\n",
      "  └── grafana_grafana_100012.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/packages/grafana-data/src/types/action.ts b/packages/grafana-data/src/types/action.ts\n",
      "     index a3cb099ebe84a..bbdfd91b4f5da 100644\n",
      "     ---------------------\n",
      "  └── grafana_grafana_100012_comments.jsonl\n",
      "     --- File preview ---\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/hashicorp\n",
      "\n",
      "/mnt/object_group/data/raw/hashicorp/terraform\n",
      "  └── hashicorp_terraform_28940.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/website/docs/configuration/functions/type.html.md b/website/docs/language/functions/type.html.md\n",
      "     similarity index 100%\n",
      "     ---------------------\n",
      "  └── hashicorp_terraform_28940_comments.jsonl\n",
      "     --- File preview ---\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/huggingface\n",
      "\n",
      "/mnt/object_group/data/raw/huggingface/transformers\n",
      "  └── huggingface_transformers_34253.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/src/transformers/tokenization_utils_base.py b/src/transformers/tokenization_utils_base.py\n",
      "     index 381f3ef497d9..03df02d21ff3 100644\n",
      "     ---------------------\n",
      "  └── huggingface_transformers_34253_comments.jsonl\n",
      "     --- File preview ---\n",
      "     {\"id\": 1816281788, \"user_login\": \"lewtun\", \"body\": \"FYI @Rocketknight1 I kept the `rstrip()` here for consistency with the prior implementation. Let me know if you want it removed.\", \"path\": \"src/transformers/tokenization_utils_base.py\", \"position\": null, \"original_position\": 12, \"commit_id\": \"0f05f9ea90bfeb2afb8da627ab75d7ae83353616\", \"original_commit_id\": \"0fd98e1a05bb987b9ee0cdcb2246de67d3665dd7\", \"diff_hunk\": \"@@ -1877,8 +1877,13 @@ def apply_chat_template(\\n                 final_message = chat[-1][\\\"content\\\"]\\n                 if isinstance(final_message, (list, tuple)):\\n                     final_message = final_message[-1][\\\"text\\\"]\\n-                final_message = final_message.strip()\\n-                rendered_chat = rendered_chat[: rendered_chat.rindex(final_message) + len(final_message)].rstrip()\\n+                try:\\n+                    final_message = final_message\\n+                    rendered_chat = rendered_chat[: rendered_chat.rindex(final_message) + len(final_message)]\\n+                except:  # noqa: E722\\n+                    # Some chat templates like Llama-3.1 trim messages before rendering, so we must do the same here.\\n+                    final_message = final_message.strip()\\n+                    rendered_chat = rendered_chat[: rendered_chat.rindex(final_message) + len(final_message)].rstrip()\", \"side\": \"RIGHT\", \"created_at\": \"2024-10-25T08:49:22+00:00\", \"updated_at\": \"2024-10-25T08:49:22+00:00\", \"html_url\": \"https://github.com/huggingface/transformers/pull/34253#discussion_r1816281788\"}\n",
      "     {\"id\": 1816793391, \"user_login\": \"lewtun\", \"body\": \"Added a regression test here @Rocketknight1 \", \"path\": \"tests/test_tokenization_common.py\", \"position\": 5, \"original_position\": 5, \"commit_id\": \"0f05f9ea90bfeb2afb8da627ab75d7ae83353616\", \"original_commit_id\": \"2cbbc1f6cc25ecab0e76605e006cb3d13f3d94df\", \"diff_hunk\": \"@@ -1357,6 +1357,38 @@ def test_continue_final_message(self):\\n                     \\\"<|im_start|>system\\\\nsystem message<|im_end|>\\\\n<|im_start|>user\\\\nuser message<|im_end|>\\\\n<|im_start|>assistant\\\\nassistant message\\\",\\n                 )\\n \\n+    @require_jinja\\n+    def test_continue_final_message_with_trim(self):\", \"side\": \"RIGHT\", \"created_at\": \"2024-10-25T14:29:39+00:00\", \"updated_at\": \"2024-10-25T14:29:39+00:00\", \"html_url\": \"https://github.com/huggingface/transformers/pull/34253#discussion_r1816793391\"}\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/jaegertracing\n",
      "\n",
      "/mnt/object_group/data/raw/jaegertracing/jaeger\n",
      "  └── jaegertracing_jaeger_1005.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/scripts/travis/kafka-integration-test.sh b/scripts/travis/kafka-integration-test.sh\n",
      "     index 71c1810a6aa..47c86976fe7 100644\n",
      "     ---------------------\n",
      "  └── jaegertracing_jaeger_1005_comments.jsonl\n",
      "     --- File preview ---\n",
      "     {\"id\": 210959808, \"user_login\": \"jpkrohling\", \"body\": \"Does it fail immediately if the port is not up, or does it block for a few ms/seconds?\", \"path\": \"scripts/travis/kafka-integration-test.sh\", \"position\": 10, \"original_position\": 10, \"commit_id\": \"7e0d9683288695385ed16cd0207ded432bb9e578\", \"original_commit_id\": \"a0c6b728ffe021940d3778efbb963d3774073612\", \"diff_hunk\": \"@@ -4,6 +4,14 @@ set -e\\n \\n docker pull spotify/kafka\\n CID=$(docker run -d -p 2181:2181 -p 9092:9092 --env ADVERTISED_HOST=localhost --env ADVERTISED_PORT=9092 --rm spotify/kafka)\\n+\\n+# Guarantees no matter what happens, docker will remove the instance at the end.\\n+trap 'docker rm -f $CID 2>/dev/null' EXIT INT TERM\\n+\\n export STORAGE=kafka\\n+while true; do\\n+    if nc -z localhost 9092; then\", \"side\": \"RIGHT\", \"created_at\": \"2018-08-17T16:11:20+00:00\", \"updated_at\": \"2018-08-17T17:25:09+00:00\", \"html_url\": \"https://github.com/jaegertracing/jaeger/pull/1005#discussion_r210959808\"}\n",
      "     {\"id\": 210963657, \"user_login\": \"yurishkuro\", \"body\": \"Looks like it blocks forever until port is available. The build still failed though.\", \"path\": \"scripts/travis/kafka-integration-test.sh\", \"position\": 10, \"original_position\": 10, \"commit_id\": \"7e0d9683288695385ed16cd0207ded432bb9e578\", \"original_commit_id\": \"a0c6b728ffe021940d3778efbb963d3774073612\", \"diff_hunk\": \"@@ -4,6 +4,14 @@ set -e\\n \\n docker pull spotify/kafka\\n CID=$(docker run -d -p 2181:2181 -p 9092:9092 --env ADVERTISED_HOST=localhost --env ADVERTISED_PORT=9092 --rm spotify/kafka)\\n+\\n+# Guarantees no matter what happens, docker will remove the instance at the end.\\n+trap 'docker rm -f $CID 2>/dev/null' EXIT INT TERM\\n+\\n export STORAGE=kafka\\n+while true; do\\n+    if nc -z localhost 9092; then\", \"side\": \"RIGHT\", \"created_at\": \"2018-08-17T16:25:42+00:00\", \"updated_at\": \"2018-08-17T17:25:09+00:00\", \"html_url\": \"https://github.com/jaegertracing/jaeger/pull/1005#discussion_r210963657\"}\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/jenkinsci\n",
      "\n",
      "/mnt/object_group/data/raw/jenkinsci/git-client-plugin\n",
      "  └── jenkinsci_git-client-plugin_1043.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/pom.xml b/pom.xml\n",
      "     index a8b5cc0476..813ed0d394 100644\n",
      "     ---------------------\n",
      "  └── jenkinsci_git-client-plugin_1043_comments.jsonl\n",
      "     --- File preview ---\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/jenkinsci/git-plugin\n",
      "  └── jenkinsci_git-plugin_1001.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/README.adoc b/README.adoc\n",
      "     index b3e4f56da5..baba232186 100644\n",
      "     ---------------------\n",
      "  └── jenkinsci_git-plugin_1001_comments.jsonl\n",
      "     --- File preview ---\n",
      "     {\"id\": 521897206, \"user_login\": \"timja\", \"body\": \"could this be the default? I can't see people wanting to use this these days\", \"path\": \"README.adoc\", \"position\": null, \"original_position\": 14, \"commit_id\": \"75defe67f9cc9b56b3df80f580b8117e26139bda\", \"original_commit_id\": \"efb3d910a89e806c8f37148d3d77865f4cc7835a\", \"diff_hunk\": \"@@ -193,6 +193,19 @@ Preserve second fetch during initial checkout::\\n   This setting is only needed if there is a bug in the redundant fetch removal logic.\\n   If you enable this setting, please report a git plugin issue that describes why you needed to enable it.\\n \\n+[[do-not-add-git-tag-action-to-jobs]]\\n+Do not add git tag action to jobs::\", \"side\": \"RIGHT\", \"created_at\": \"2020-11-12T07:48:36+00:00\", \"updated_at\": \"2020-11-14T17:15:26+00:00\", \"html_url\": \"https://github.com/jenkinsci/git-plugin/pull/1001#discussion_r521897206\"}\n",
      "     {\"id\": 521897672, \"user_login\": \"timja\", \"body\": \"new screenshot looks way nicer \\ud83d\\ude04 \", \"path\": \"README.adoc\", \"position\": 13, \"original_position\": 13, \"commit_id\": \"75defe67f9cc9b56b3df80f580b8117e26139bda\", \"original_commit_id\": \"efb3d910a89e806c8f37148d3d77865f4cc7835a\", \"diff_hunk\": \"@@ -193,6 +193,19 @@ Preserve second fetch during initial checkout::\\n   This setting is only needed if there is a bug in the redundant fetch removal logic.\\n   If you enable this setting, please report a git plugin issue that describes why you needed to enable it.\\n \\n+[[do-not-add-git-tag-action-to-jobs]]\", \"side\": \"RIGHT\", \"created_at\": \"2020-11-12T07:49:36+00:00\", \"updated_at\": \"2020-11-14T17:15:26+00:00\", \"html_url\": \"https://github.com/jenkinsci/git-plugin/pull/1001#discussion_r521897672\"}\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/kubernetes\n",
      "\n",
      "/mnt/object_group/data/raw/kubernetes/kubernetes\n",
      "  └── kubernetes_kubernetes_129070.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/test/e2e/framework/pod/wait.go b/test/e2e/framework/pod/wait.go\n",
      "     index 537d59c32241a..92eec8b2c1417 100644\n",
      "     ---------------------\n",
      "  └── kubernetes_kubernetes_129070_comments.jsonl\n",
      "     --- File preview ---\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/microsoft\n",
      "\n",
      "/mnt/object_group/data/raw/microsoft/vscode\n",
      "  └── microsoft_vscode_180546.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/src/vs/workbench/contrib/tasks/browser/abstractTaskService.ts b/src/vs/workbench/contrib/tasks/browser/abstractTaskService.ts\n",
      "     index 4549df0584c9e..4392fd3d47330 100644\n",
      "     ---------------------\n",
      "  └── microsoft_vscode_180546_comments.jsonl\n",
      "     --- File preview ---\n",
      "     {\"id\": 1184456339, \"user_login\": \"meganrogge\", \"body\": \"is there a reason we don't want to also check `&& terminalData && terminalData.promise)` here before setting `this._lastTask = this._currentTask`?\", \"path\": \"src/vs/workbench/contrib/tasks/browser/terminalTaskSystem.ts\", \"position\": 16, \"original_position\": 14, \"commit_id\": \"826d3ffb9d4c8c353508fad7723b9757b26e10cc\", \"original_commit_id\": \"d3a1f08be9b0de553a40be2e6723c1d94aefbd24\", \"diff_hunk\": \"@@ -286,17 +286,20 @@ export class TerminalTaskSystem extends Disposable implements ITaskSystem {\\n \\tpublic run(task: Task, resolver: ITaskResolver, trigger: string = Triggers.command): ITaskExecuteResult {\\n \\t\\ttask = task.clone(); // A small amount of task state is stored in the task (instance) and tasks passed in to run may have that set already.\\n \\t\\tconst recentTaskKey = task.getRecentlyUsedKey() ?? '';\\n-\\t\\tconst validInstance = task.runOptions && task.runOptions.instanceLimit && this._instances[recentTaskKey] && this._instances[recentTaskKey].instances < task.runOptions.instanceLimit;\\n+\\t\\tconst validInstance = !this._instances[recentTaskKey] || this._instances[recentTaskKey].instances < ((task.runOptions && task.runOptions.instanceLimit) ?? 0);\\n \\t\\tconst instance = this._instances[recentTaskKey] ? this._instances[recentTaskKey].instances : 0;\\n \\t\\tthis._currentTask = new VerifiedTask(task, resolver, trigger);\\n \\t\\tif (instance > 0) {\\n \\t\\t\\ttask.instance = this._instances[recentTaskKey].counter;\\n \\t\\t}\\n \\t\\tconst lastTaskInstance = this.getLastInstance(task);\\n \\t\\tconst terminalData = lastTaskInstance ? this._activeTasks[lastTaskInstance.getMapKey()] : undefined;\\n-\\t\\tif (terminalData && terminalData.promise && !validInstance) {\\n+\\t\\tif (!validInstance) {\", \"side\": \"RIGHT\", \"created_at\": \"2023-05-04T01:34:26+00:00\", \"updated_at\": \"2023-05-04T01:34:27+00:00\", \"html_url\": \"https://github.com/microsoft/vscode/pull/180546#discussion_r1184456339\"}\n",
      "     {\"id\": 1185175066, \"user_login\": \"markw65\", \"body\": \"For one thing, `promise` isn't nullable, so checking `terminalData.promise` was just redundant.\\r\\n\\r\\nBut this was pretty much the point of this change. If we know that we've exceeded the instance count, it doesn't matter whether there's an entry in _activeTasks or not (especially since prior to #180617 there was a race, and _activeTasks doesn't get updated until some time after the task has been launched).\\r\\n\\r\\nSo the changes here are no longer strictly needed (but we do need to undo the newly added `&& !task.configurationProperties.dependsOn?.length`), but I think it's worth keeping anyway. The logic here (maintained in `_instances`) is self contained; we shouldn't ignore it because of some external conditions.\", \"path\": \"src/vs/workbench/contrib/tasks/browser/terminalTaskSystem.ts\", \"position\": 16, \"original_position\": 14, \"commit_id\": \"826d3ffb9d4c8c353508fad7723b9757b26e10cc\", \"original_commit_id\": \"d3a1f08be9b0de553a40be2e6723c1d94aefbd24\", \"diff_hunk\": \"@@ -286,17 +286,20 @@ export class TerminalTaskSystem extends Disposable implements ITaskSystem {\\n \\tpublic run(task: Task, resolver: ITaskResolver, trigger: string = Triggers.command): ITaskExecuteResult {\\n \\t\\ttask = task.clone(); // A small amount of task state is stored in the task (instance) and tasks passed in to run may have that set already.\\n \\t\\tconst recentTaskKey = task.getRecentlyUsedKey() ?? '';\\n-\\t\\tconst validInstance = task.runOptions && task.runOptions.instanceLimit && this._instances[recentTaskKey] && this._instances[recentTaskKey].instances < task.runOptions.instanceLimit;\\n+\\t\\tconst validInstance = !this._instances[recentTaskKey] || this._instances[recentTaskKey].instances < ((task.runOptions && task.runOptions.instanceLimit) ?? 0);\\n \\t\\tconst instance = this._instances[recentTaskKey] ? this._instances[recentTaskKey].instances : 0;\\n \\t\\tthis._currentTask = new VerifiedTask(task, resolver, trigger);\\n \\t\\tif (instance > 0) {\\n \\t\\t\\ttask.instance = this._instances[recentTaskKey].counter;\\n \\t\\t}\\n \\t\\tconst lastTaskInstance = this.getLastInstance(task);\\n \\t\\tconst terminalData = lastTaskInstance ? this._activeTasks[lastTaskInstance.getMapKey()] : undefined;\\n-\\t\\tif (terminalData && terminalData.promise && !validInstance) {\\n+\\t\\tif (!validInstance) {\", \"side\": \"RIGHT\", \"created_at\": \"2023-05-04T15:13:23+00:00\", \"updated_at\": \"2023-05-04T15:13:23+00:00\", \"html_url\": \"https://github.com/microsoft/vscode/pull/180546#discussion_r1185175066\"}\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/prometheus\n",
      "\n",
      "/mnt/object_group/data/raw/prometheus/prometheus\n",
      "  └── prometheus_prometheus_10347.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/CHANGELOG.md b/CHANGELOG.md\n",
      "     index 7d6edc3664a..406abe48a52 100644\n",
      "     ---------------------\n",
      "  └── prometheus_prometheus_10347_comments.jsonl\n",
      "     --- File preview ---\n",
      "     {\"id\": 813463529, \"user_login\": \"LeviHarrison\", \"body\": \"I think this might fall under the `[CHANGE]` category because it removes the old Jaeger tracing support. Also, maybe that migration aspect of it should be made more clear in the description.\", \"path\": \"CHANGELOG.md\", \"position\": null, \"original_position\": 4, \"commit_id\": \"db1737f91995814b75803d2a5b954d921750b9fa\", \"original_commit_id\": \"de2129b9ab50f59a96af87de5b477d161d51c924\", \"diff_hunk\": \"@@ -1,3 +1,18 @@\\n+## 2.34.0-rc.0 / 2022-02-24\\n+\\n+* [CHANGE] UI: Classic UI removed. #10208\\n+* [FEATURE] Tracing: OpenTelemetry based tracing. #9724, #10203, #10276\", \"side\": \"RIGHT\", \"created_at\": \"2022-02-24T01:08:33+00:00\", \"updated_at\": \"2022-02-24T01:10:21+00:00\", \"html_url\": \"https://github.com/prometheus/prometheus/pull/10347#discussion_r813463529\"}\n",
      "     {\"id\": 813463727, \"user_login\": \"LeviHarrison\", \"body\": \"Does #10338 need to be included in this list?\", \"path\": \"CHANGELOG.md\", \"position\": null, \"original_position\": 4, \"commit_id\": \"db1737f91995814b75803d2a5b954d921750b9fa\", \"original_commit_id\": \"de2129b9ab50f59a96af87de5b477d161d51c924\", \"diff_hunk\": \"@@ -1,3 +1,18 @@\\n+## 2.34.0-rc.0 / 2022-02-24\\n+\\n+* [CHANGE] UI: Classic UI removed. #10208\\n+* [FEATURE] Tracing: OpenTelemetry based tracing. #9724, #10203, #10276\", \"side\": \"RIGHT\", \"created_at\": \"2022-02-24T01:09:04+00:00\", \"updated_at\": \"2022-02-24T01:10:21+00:00\", \"html_url\": \"https://github.com/prometheus/prometheus/pull/10347#discussion_r813463727\"}\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/tensorflow\n",
      "\n",
      "/mnt/object_group/data/raw/tensorflow/tensorflow\n",
      "  └── tensorflow_tensorflow_50020.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/tensorflow/compiler/mlir/hlo/BUILD b/tensorflow/compiler/mlir/hlo/BUILD\n",
      "     index abae4e58ce15c9..345cf2e961cdad 100644\n",
      "     ---------------------\n",
      "  └── tensorflow_tensorflow_50020_comments.jsonl\n",
      "     --- File preview ---\n",
      "     {\"id\": 649365973, \"user_login\": \"joker-eph\", \"body\": \"consumered > consumed\", \"path\": \"tensorflow/compiler/mlir/hlo/include/mlir-hlo/Dialect/mhlo/transforms/fusion_utils.h\", \"position\": null, \"original_position\": 40, \"commit_id\": \"923c8d61f7fe00a2a0df22d5be396508f0667964\", \"original_commit_id\": \"4e73f3833449e174b06b3a62b09704b706b8a810\", \"diff_hunk\": \"@@ -0,0 +1,239 @@\\n+/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\\n+\\n+Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n+you may not use this file except in compliance with the License.\\n+You may obtain a copy of the License at\\n+\\n+    http://www.apache.org/licenses/LICENSE-2.0\\n+\\n+Unless required by applicable law or agreed to in writing, software\\n+distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n+See the License for the specific language governing permissions and\\n+limitations under the License.\\n+==============================================================================*/\\n+\\n+#ifndef TENSORFLOW_COMPILER_MLIR_HLO_INCLUDE_MLIR_HLO_DIALECT_MHLO_TRANSFORMS_FUSION_UTILS_H_\\n+#define TENSORFLOW_COMPILER_MLIR_HLO_INCLUDE_MLIR_HLO_DIALECT_MHLO_TRANSFORMS_FUSION_UTILS_H_\\n+\\n+#include <memory>\\n+#include <vector>\\n+\\n+#include \\\"llvm/ADT/EquivalenceClasses.h\\\"\\n+#include \\\"llvm/Support/Debug.h\\\"\\n+#include \\\"mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h\\\"\\n+#include \\\"mlir/Dialect/StandardOps/IR/Ops.h\\\"  // TF:llvm-project\\n+\\n+// This file implements some helper functions and classes used to do fusion\\n+// & code generation.\\n+\\n+namespace mlir {\\n+namespace lmhlo {\\n+\\n+// kLoop fusion template satisfies:\\n+//   - all ops in the fusion pattern are element-wise.\\n+//   - all the shapes of outputs of fusion pattern are same or have same number\\n+//   of elements, and thus can fit into a same parallel loop.\\n+//\\n+// kInput fusion template satisfies:\\n+//   - any op in the fusion pattern is either element-wise or a reduction.\\n+//   - if a op is a reduction, its output cannot be consumered by other\", \"side\": \"RIGHT\", \"created_at\": \"2021-06-10T16:58:13+00:00\", \"updated_at\": \"2021-06-10T19:22:55+00:00\", \"html_url\": \"https://github.com/tensorflow/tensorflow/pull/50020#discussion_r649365973\"}\n",
      "     {\"id\": 649366770, \"user_login\": \"joker-eph\", \"body\": \"Y\", \"path\": \"tensorflow/compiler/mlir/hlo/include/mlir-hlo/Dialect/mhlo/transforms/fusion_utils.h\", \"position\": 41, \"original_position\": 41, \"commit_id\": \"923c8d61f7fe00a2a0df22d5be396508f0667964\", \"original_commit_id\": \"4e73f3833449e174b06b3a62b09704b706b8a810\", \"diff_hunk\": \"@@ -0,0 +1,239 @@\\n+/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\\n+\\n+Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n+you may not use this file except in compliance with the License.\\n+You may obtain a copy of the License at\\n+\\n+    http://www.apache.org/licenses/LICENSE-2.0\\n+\\n+Unless required by applicable law or agreed to in writing, software\\n+distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n+See the License for the specific language governing permissions and\\n+limitations under the License.\\n+==============================================================================*/\\n+\\n+#ifndef TENSORFLOW_COMPILER_MLIR_HLO_INCLUDE_MLIR_HLO_DIALECT_MHLO_TRANSFORMS_FUSION_UTILS_H_\\n+#define TENSORFLOW_COMPILER_MLIR_HLO_INCLUDE_MLIR_HLO_DIALECT_MHLO_TRANSFORMS_FUSION_UTILS_H_\\n+\\n+#include <memory>\\n+#include <vector>\\n+\\n+#include \\\"llvm/ADT/EquivalenceClasses.h\\\"\\n+#include \\\"llvm/Support/Debug.h\\\"\\n+#include \\\"mlir-hlo/Dialect/mhlo/IR/lhlo_ops.h\\\"\\n+#include \\\"mlir/Dialect/StandardOps/IR/Ops.h\\\"  // TF:llvm-project\\n+\\n+// This file implements some helper functions and classes used to do fusion\\n+// & code generation.\\n+\\n+namespace mlir {\\n+namespace lmhlo {\\n+\\n+// kLoop fusion template satisfies:\\n+//   - all ops in the fusion pattern are element-wise.\\n+//   - all the shapes of outputs of fusion pattern are same or have same number\\n+//   of elements, and thus can fit into a same parallel loop.\\n+//\\n+// kInput fusion template satisfies:\\n+//   - any op in the fusion pattern is either element-wise or a reduction.\\n+//   - if a op is a reduction, its output cannot be consumered by other\\n+//     ops in the same fusion pattern.\", \"side\": \"RIGHT\", \"created_at\": \"2021-06-10T16:59:17+00:00\", \"updated_at\": \"2021-06-10T19:22:56+00:00\", \"html_url\": \"https://github.com/tensorflow/tensorflow/pull/50020#discussion_r649366770\"}\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n",
      "\n",
      "/mnt/object_group/data/raw/vercel\n",
      "\n",
      "/mnt/object_group/data/raw/vercel/next.js\n",
      "  └── vercel_next.js_73057.diff\n",
      "     --- File preview ---\n",
      "     diff --git a/bench/heavy-npm-deps/next.config.mjs b/bench/heavy-npm-deps/next.config.mjs\n",
      "     index 02ab1381cc78b..ca1dc40a4b212 100644\n",
      "     ---------------------\n",
      "  └── vercel_next.js_73057_comments.jsonl\n",
      "     --- File preview ---\n",
      "     ---------------------\n",
      "  ... (more files hidden)\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/mnt/object_group/data\"\n",
    "preview_lines = 2  # number of lines/content lines to print\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    print(f\"\\n{dirpath}\")\n",
    "    for fname in filenames[:2]:  # preview up to 5 files\n",
    "        full_path = os.path.join(dirpath, fname)\n",
    "        print(f\"  └── {fname}\")\n",
    "        \n",
    "        try:\n",
    "            with open(full_path, 'r') as f:\n",
    "                print(\"     --- File preview ---\")\n",
    "                for i, line in enumerate(f):\n",
    "                    print(\"     \" + line.strip())\n",
    "                    if i + 1 >= preview_lines:\n",
    "                        break\n",
    "                print(\"     ---------------------\")\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"     [Binary or non-text file — skipped]\")\n",
    "        except Exception as e:\n",
    "            print(f\"     [Error reading file: {e}]\")\n",
    "\n",
    "    if len(filenames) > 5:\n",
    "        print(\"  ... (more files hidden)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a501fd69-1265-49c4-a033-f649666fa637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    {\"comment_id\": 74291026, \"comment_user_login\": \"vikerman\", \"comment_body\": \"Is there a better way to avoid having this in different places?\\n\", \"comment_created_at\": \"2016-08-10T17:30:42+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10620#discussion_r74291026\", \"comment_path\": \"modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"comment_position\": 10, \"comment_original_position\": 10, \"comment_commit_id\": \"ee8e802b7bc25eafbe54109b3924e9dbc36dce11\", \"comment_original_commit_id\": \"ee8e802b7bc25eafbe54109b3924e9dbc36dce11\", \"diff_line_content\": \"}\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 15, \"diff_hunk_header\": \"\", \"diff\": \"@@ -6,10 +6,13 @@\\n  * found in the LICENSE file at https://angular.io/license\\n  */\\n \\n-import {unimplemented} from '../../facade/exceptions';\\n+import {BaseException} from '@angular/core';\\n import {isPresent} from '../../facade/lang';\\n import {AbstractControl} from '../model';\\n \\n+function unimplemented(): any {\\n+  throw new BaseException('unimplemented');\", \"side\": \"RIGHT\", \"line_offset\": 9, \"diff_file_source\": \"a/modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"diff_file_target\": \"b/modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74305223, \"comment_user_login\": \"alexeagle\", \"comment_body\": \"we could export it in the public API but that's not nice.\\nOr we could inline the method and delete it.\\n\", \"comment_created_at\": \"2016-08-10T18:42:59+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10620#discussion_r74305223\", \"comment_path\": \"modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"comment_position\": 10, \"comment_original_position\": 10, \"comment_commit_id\": \"ee8e802b7bc25eafbe54109b3924e9dbc36dce11\", \"comment_original_commit_id\": \"ee8e802b7bc25eafbe54109b3924e9dbc36dce11\", \"diff_line_content\": \"}\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 15, \"diff_hunk_header\": \"\", \"diff\": \"@@ -6,10 +6,13 @@\\n  * found in the LICENSE file at https://angular.io/license\\n  */\\n \\n-import {unimplemented} from '../../facade/exceptions';\\n+import {BaseException} from '@angular/core';\\n import {isPresent} from '../../facade/lang';\\n import {AbstractControl} from '../model';\\n \\n+function unimplemented(): any {\\n+  throw new BaseException('unimplemented');\", \"side\": \"RIGHT\", \"line_offset\": 9, \"diff_file_source\": \"a/modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"diff_file_target\": \"b/modules/@angular/common/src/forms-deprecated/directives/abstract_control_directive.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74523490, \"comment_user_login\": \"vicb\", \"comment_body\": \"const\\n\", \"comment_created_at\": \"2016-08-11T23:43:20+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74523490\", \"comment_path\": \"modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"comment_position\": 36, \"comment_original_position\": 36, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"91f50b2f513f99cf56b7406b3a74066e128b9c7d\", \"diff_line_content\": \"    it('should support i18n for content tags', () => {\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 79, \"diff_hunk_header\": \"describe('template codegen output', () => {\", \"diff\": \"@@ -44,24 +44,40 @@ describe('template codegen output', () => {\\n   it('should support ngIf', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     compFixture.componentInstance.ctxBool = true;\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(3);\\n+    expect(debugElement.children.length).toBe(4);\\n     expect(debugElement.children[2].injector.get(MultipleComponentsMyComp)).toBeTruthy();\\n   });\\n \\n   it('should support ngFor', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     // test NgFor\\n     compFixture.componentInstance.ctxArr = [1, 2];\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(4);\\n+    expect(debugElement.children.length).toBe(5);\\n     expect(debugElement.children[2].attributes['value']).toBe('1');\\n     expect(debugElement.children[3].attributes['value']).toBe('2');\\n   });\\n+\\n+  describe('i18n', () => {\\n+    it('should support i18n for content tags', () => {\\n+      var compFixture = createComponent(BasicComp);\\n+      expect(compFixture.componentInstance.ctxLocale).toEqual('FI');\\n+    });\\n+\\n+    it('should support i18n for content tags', () => {\\n+      var compFixture = createComponent(BasicComp);\", \"side\": \"RIGHT\", \"line_offset\": 35, \"diff_file_source\": \"a/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74523504, \"comment_user_login\": \"vicb\", \"comment_body\": \"const\\n\", \"comment_created_at\": \"2016-08-11T23:43:27+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74523504\", \"comment_path\": \"modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"comment_position\": 31, \"comment_original_position\": 31, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"91f50b2f513f99cf56b7406b3a74066e128b9c7d\", \"diff_line_content\": \"    it('should inject the translations format into the component', () => {\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 74, \"diff_hunk_header\": \"describe('template codegen output', () => {\", \"diff\": \"@@ -44,24 +44,40 @@ describe('template codegen output', () => {\\n   it('should support ngIf', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     compFixture.componentInstance.ctxBool = true;\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(3);\\n+    expect(debugElement.children.length).toBe(4);\\n     expect(debugElement.children[2].injector.get(MultipleComponentsMyComp)).toBeTruthy();\\n   });\\n \\n   it('should support ngFor', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     // test NgFor\\n     compFixture.componentInstance.ctxArr = [1, 2];\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(4);\\n+    expect(debugElement.children.length).toBe(5);\\n     expect(debugElement.children[2].attributes['value']).toBe('1');\\n     expect(debugElement.children[3].attributes['value']).toBe('2');\\n   });\\n+\\n+  describe('i18n', () => {\\n+    it('should support i18n for content tags', () => {\\n+      var compFixture = createComponent(BasicComp);\", \"side\": \"RIGHT\", \"line_offset\": 30, \"diff_file_source\": \"a/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74526501, \"comment_user_login\": \"vicb\", \"comment_body\": \"fi\\n\", \"comment_created_at\": \"2016-08-12T00:18:35+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74526501\", \"comment_path\": \"modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"comment_position\": 32, \"comment_original_position\": 32, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"7333b4c6d9527a1a6b812ab6eea2797f228d03bd\", \"diff_line_content\": \"      const compFixture = createComponent(BasicComp);\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 75, \"diff_hunk_header\": \"describe('template codegen output', () => {\", \"diff\": \"@@ -44,24 +44,45 @@ describe('template codegen output', () => {\\n   it('should support ngIf', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     compFixture.componentInstance.ctxBool = true;\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(3);\\n+    expect(debugElement.children.length).toBe(4);\\n     expect(debugElement.children[2].injector.get(MultipleComponentsMyComp)).toBeTruthy();\\n   });\\n \\n   it('should support ngFor', () => {\\n     var compFixture = createComponent(BasicComp);\\n     var debugElement = compFixture.debugElement;\\n-    expect(debugElement.children.length).toBe(2);\\n+    expect(debugElement.children.length).toBe(3);\\n \\n     // test NgFor\\n     compFixture.componentInstance.ctxArr = [1, 2];\\n     compFixture.detectChanges();\\n-    expect(debugElement.children.length).toBe(4);\\n+    expect(debugElement.children.length).toBe(5);\\n     expect(debugElement.children[2].attributes['value']).toBe('1');\\n     expect(debugElement.children[3].attributes['value']).toBe('2');\\n   });\\n+\\n+  describe('i18n', () => {\\n+    it('should inject the locale into the component', () => {\\n+      const compFixture = createComponent(BasicComp);\\n+      expect(compFixture.componentInstance.ctxLocale).toEqual('FI');\", \"side\": \"RIGHT\", \"line_offset\": 31, \"diff_file_source\": \"a/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/integrationtest/test/basic_spec.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74526531, \"comment_user_login\": \"vicb\", \"comment_body\": \"remove !\\n\", \"comment_created_at\": \"2016-08-12T00:19:06+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74526531\", \"comment_path\": \"modules/@angular/compiler-cli/src/codegen.ts\", \"comment_position\": 36, \"comment_original_position\": 36, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"7333b4c6d9527a1a6b812ab6eea2797f228d03bd\", \"diff_line_content\": \"    const reflectorHost = new ReflectorHost(program, compilerHost, options, reflectorHostContext);\\n\", \"diff_line_type\": \"context\", \"diff_line_source_no\": 132, \"diff_line_target_no\": 142, \"diff_hunk_header\": \"export class CodeGenerator {\", \"diff\": \"@@ -88,6 +93,35 @@ export class CodeGenerator {\\n     return path.join(this.options.genDir, relativePath);\\n   }\\n \\n+  private _constructTranslationBundle(fileMetas: any[], analyzedNgModules: any): Promise<any> {\", \"side\": \"RIGHT\", \"line_offset\": 11, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/codegen.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/codegen.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74526731, \"comment_user_login\": \"vicb\", \"comment_body\": \"append at the end to make diff readable\\n\", \"comment_created_at\": \"2016-08-12T00:21:49+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74526731\", \"comment_path\": \"modules/@angular/compiler-cli/src/codegen.ts\", \"comment_position\": 26, \"comment_original_position\": 26, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"7333b4c6d9527a1a6b812ab6eea2797f228d03bd\", \"diff_line_content\": \"      }\\n\", \"diff_line_type\": \"context\", \"diff_line_source_no\": 129, \"diff_line_target_no\": 132, \"diff_hunk_header\": \"export class CodeGenerator {\", \"diff\": \"@@ -32,7 +35,9 @@ const PREAMBLE = `/**\\n \\n export class CodeGenerator {\\n   constructor(\\n-      private options: AngularCompilerOptions, private program: ts.Program,\\n+      private options: AngularCompilerOptions, private transContent: string,\", \"side\": \"RIGHT\", \"line_offset\": 1, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/codegen.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/codegen.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74527376, \"comment_user_login\": \"vicb\", \"comment_body\": \"This is the only line that you should keep beside loading the file\\n\", \"comment_created_at\": \"2016-08-12T00:30:39+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74527376\", \"comment_path\": \"modules/@angular/compiler-cli/src/codegen.ts\", \"comment_position\": 46, \"comment_original_position\": 130, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"7333b4c6d9527a1a6b812ab6eea2797f228d03bd\", \"diff_line_content\": \"        new NgModuleCompiler(), new TypeScriptEmitter(reflectorHost), cliOptions.locale,\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 164, \"diff_hunk_header\": \"export class CodeGenerator {\", \"diff\": \"@@ -132,7 +175,7 @@ export class CodeGenerator {\\n     const reflectorHost = new ReflectorHost(program, compilerHost, options, reflectorHostContext);\\n     const staticReflector = new StaticReflector(reflectorHost);\\n     StaticAndDynamicReflectionCapabilities.install(staticReflector);\\n-    const htmlParser = new compiler.i18n.HtmlParser(new HtmlParser());\\n+    const htmlParser = new compiler.i18n.HtmlParser(new HtmlParser(), transContent);\", \"side\": \"RIGHT\", \"line_offset\": 3, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/codegen.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/codegen.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74528827, \"comment_user_login\": \"vicb\", \"comment_body\": \"Id\\n\", \"comment_created_at\": \"2016-08-12T00:51:47+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74528827\", \"comment_path\": \"modules/@angular/compiler-cli/integrationtest/src/basic.ts\", \"comment_position\": 15, \"comment_original_position\": 15, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"e7940fc0e83c9d0a549891774db0a609ec591c19\", \"diff_line_content\": \"  }\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 30, \"diff_hunk_header\": \"export class BasicComp {\", \"diff\": \"@@ -23,5 +23,9 @@ export class BasicComp {\\n   ctxProp: string;\\n   ctxBool: boolean;\\n   ctxArr: any[] = [];\\n-  constructor() { this.ctxProp = 'initialValue'; }\\n+  constructor(\\n+      @Inject(LOCALE_ID) public localeID: string,\", \"side\": \"RIGHT\", \"line_offset\": 7, \"diff_file_source\": \"a/modules/@angular/compiler-cli/integrationtest/src/basic.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/integrationtest/src/basic.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74528853, \"comment_user_login\": \"vicb\", \"comment_body\": \"only add the format\\n\", \"comment_created_at\": \"2016-08-12T00:52:10+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74528853\", \"comment_path\": \"modules/@angular/compiler-cli/src/extract_i18n.ts\", \"comment_position\": 6, \"comment_original_position\": 6, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"e7940fc0e83c9d0a549891774db0a609ec591c19\", \"diff_line_content\": \"  const extractor = Extractor.create(ngOptions, cliOptions.i18nFormat, program, host);\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 33, \"diff_hunk_header\": \"import {StaticAndDynamicReflectionCapabilities} from './static_reflection_capabi\", \"diff\": \"@@ -28,8 +28,9 @@ import {StaticAndDynamicReflectionCapabilities} from './static_reflection_capabi\\n import {StaticReflector, StaticSymbol} from './static_reflector';\\n \\n function extract(\\n-    ngOptions: tsc.AngularCompilerOptions, program: ts.Program, host: ts.CompilerHost) {\\n-  const extractor = Extractor.create(ngOptions, program, host);\\n+    ngOptions: tsc.AngularCompilerOptions, cliOptions: tsc.CliOptions, program: ts.Program,\", \"side\": \"RIGHT\", \"line_offset\": 5, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/extract_i18n.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/extract_i18n.ts\", \"repo\": \"angular/angular\"}\n",
      "    {\"comment_id\": 74530724, \"comment_user_login\": \"vicb\", \"comment_body\": \"`, null, null` would be more semantically correct\\n\", \"comment_created_at\": \"2016-08-12T01:22:30+00:00\", \"comment_html_url\": \"https://github.com/angular/angular/pull/10622#discussion_r74530724\", \"comment_path\": \"modules/@angular/compiler-cli/src/extract_i18n.ts\", \"comment_position\": 37, \"comment_original_position\": 37, \"comment_commit_id\": \"616c5c56924b77bc0ef539d01d1cf3596c0da87f\", \"comment_original_commit_id\": \"6781377043d6eae20d6504b83a121ebde353f043\", \"diff_line_content\": \"}\\n\", \"diff_line_type\": \"added\", \"diff_line_source_no\": null, \"diff_line_target_no\": 196, \"diff_hunk_header\": \"interface FileMetadata {\", \"diff\": \"@@ -163,7 +164,7 @@ export class Extractor {\\n         config, console, elementSchemaRegistry, staticReflector);\\n     const offlineCompiler = new compiler.OfflineCompiler(\\n         resolver, normalizer, tmplParser, new StyleCompiler(urlResolver), new ViewCompiler(config),\\n-        new NgModuleCompiler(), new TypeScriptEmitter(reflectorHost));\\n+        new NgModuleCompiler(), new TypeScriptEmitter(reflectorHost), '', translationsFormat);\", \"side\": \"RIGHT\", \"line_offset\": 12, \"diff_file_source\": \"a/modules/@angular/compiler-cli/src/extract_i18n.ts\", \"diff_file_target\": \"b/modules/@angular/compiler-cli/src/extract_i18n.ts\", \"repo\": \"angular/angular\"}\n"
     ]
    }
   ],
   "source": [
    "train = \"/mnt/object_group/data/processed/train.jsonl.gz\"\n",
    "with gzip.open(train, 'rt', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(\"    \" + line.strip())\n",
    "        if i >= 10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "483d6154-9d34-468f-ae56-fd0301437a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/mnt/object_group/data/processed\")  # Adjust as needed\n",
    "\n",
    "def load_samples(limit_per_split=10):\n",
    "    diff_samples = []\n",
    "    for repo_dir in DATA_ROOT.iterdir():\n",
    "        if not repo_dir.is_dir():\n",
    "            continue\n",
    "        for pr_dir in (repo_dir / \"diff\").iterdir():\n",
    "            pr_id = pr_dir.name\n",
    "            diff_file = pr_dir\n",
    "            comments_file = DATA_ROOT / repo_dir.name / \"comments\" / f\"{repo_dir.name}_{pr_id}_comments.jsonl\"\n",
    "\n",
    "            if not diff_file.exists() or not comments_file.exists():\n",
    "                continue\n",
    "\n",
    "            with open(diff_file, \"r\", encoding=\"utf-8\") as df:\n",
    "                diff_content = df.read()\n",
    "\n",
    "            with open(comments_file, \"r\", encoding=\"utf-8\") as cf:\n",
    "                for line in cf:\n",
    "                    try:\n",
    "                        comment = json.loads(line)\n",
    "                        offset = comment.get(\"original_position\")\n",
    "                        side = comment.get(\"side\", \"RIGHT\")\n",
    "                        body = comment.get(\"body\", \"\").strip()\n",
    "                        if offset is not None and body:\n",
    "                            sample = {\n",
    "                                \"input\": f\"<DIFF>\\n{diff_content}\\n</DIFF>\\n<COMMENT side=\\\"{side}\\\" offset=\\\"{offset}\\\">\",\n",
    "                                \"output\": body\n",
    "                            }\n",
    "                            diff_samples.append(sample)\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "\n",
    "    random.shuffle(diff_samples)\n",
    "    return {\n",
    "        \"train\": diff_samples[:limit_per_split],\n",
    "        \"test\": diff_samples[limit_per_split:2*limit_per_split],\n",
    "        \"eval\": diff_samples[2*limit_per_split:3*limit_per_split],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0fad3e5-a39c-42b2-af16-f18d85946d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_gz(file_path, limit):\n",
    "    samples = []\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= limit:\n",
    "                break\n",
    "            entry = json.loads(line)\n",
    "            prompt = f\"<DIFF>\\n{entry['diff']}\\n</DIFF>\\n\"\n",
    "            comment = f\"<COMMENT side=\\\"{entry['side']}\\\" offset=\\\"{entry['line_offset']}\\\">{entry['comment_body']}\"\n",
    "            samples.append({'input': prompt, 'label': comment})\n",
    "    return samples\n",
    "\n",
    "train_data = load_jsonl_gz(\"/mnt/object_group/data/processed/train.jsonl.gz\", 10)\n",
    "test_data  = load_jsonl_gz(\"/mnt/object_group/data/processed/test.jsonl.gz\", 8)\n",
    "eval_data  = load_jsonl_gz(\"/mnt/object_group/data/processed/val.jsonl.gz\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2ddda06-1c1e-4d44-a915-d6253ea8bb84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aac47a0d-db7f-40bc-84ce-d02d66eb7617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005ef98341364f50af3ec49c217964bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2493498499d444f497ae18d74f87bf5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd76abe9b5a43aa8268e3363647a787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-Coder-V2-Lite-Base\")\n",
    "def tokenize(example):\n",
    "    input = tokenizer(example['input'], truncation=True, padding='max_length', max_length=512)\n",
    "    label = tokenizer(example['label'], truncation=True, padding='max_length', max_length=128)\n",
    "    input['labels'] = label['input_ids']\n",
    "    return input\n",
    "\n",
    "train_ds = Dataset.from_list(train_data).map(tokenize)\n",
    "test_ds  = Dataset.from_list(test_data).map(tokenize)\n",
    "eval_ds  = Dataset.from_list(eval_data).map(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2791263-9c1b-4351-b9bb-5b41ac39ccd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c794df7-b26e-468e-a00c-fabdb955cce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e340b44c10584262b67425814fc768c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 2.75 MiB is free. Process 11898 has 79.24 GiB memory in use. Of the allocated memory 78.78 GiB is allocated by PyTorch, and 63.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeepseek-ai/DeepSeek-Coder-V2-Lite-Base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m lora_cfg \u001b[38;5;241m=\u001b[39m LoraConfig(\n\u001b[1;32m      3\u001b[0m     task_type\u001b[38;5;241m=\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mCAUSAL_LM,\n\u001b[1;32m      4\u001b[0m     r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     target_modules\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgate_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdown_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Add this\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m get_peft_model(base_model, lora_cfg)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/modeling_utils.py:3698\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3697\u001b[0m         )\n\u001b[0;32m-> 3698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 2.75 MiB is free. Process 11898 has 79.24 GiB memory in use. Of the allocated memory 78.78 GiB is allocated by PyTorch, and 63.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-Coder-V2-Lite-Base\", trust_remote_code = True).to(\"cuda\")\n",
    "lora_cfg = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]  # Add this\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba1eb9-8e70-4c05-a707-4ca3b993c5e9",
   "metadata": {},
   "source": [
    "We get CUDA Out of Memory error even to get te pef model, hence do optimizations to reduce the size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1eaec6-225f-4327-925f-39cb46e7f3b9",
   "metadata": {},
   "source": [
    "### ONNX Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d7f8a-bad8-49b9-aa51-a3fe5ad1e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f3e12-bc39-466d-b729-f12af218c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = \"deepseek-ai/DeepSeek-Coder-V2-Lite-Base\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_arch, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f20285-cbc8-4cc3-95c3-fd4bd00bb73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(model_path, map_location=device, weights_only=False)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afbca1-17e4-4346-8740-b411687589f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3026405-513b-4126-838c-9fa4dd82ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_model_path = \"/mnt/object/models/finetuned_deepseek_onnx/model.onnx\"\n",
    "# Path(\"/mnt/object/models/finetuned_deepseek_onnx\").mkdir(parents=True, exist_ok=True)\n",
    "onnx_model_path = \"models/finetunedDeepseekcoV2.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfe0a8-2882-49ba-a4f1-2dae1712792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input token count\n",
    "idx = 9\n",
    "sample_input = train_data[idx]['input']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-Coder-V2-Lite-Base\", trust_remote_code=True)\n",
    "tokens = tokenizer(sample_input, return_tensors=\"pt\")\n",
    "print(\"Token count:\", tokens['input_ids'].shape[1])\n",
    "print(train_data[idx]['input'] + \"\\n\" + train_data[idx]['label'])\n",
    "# print(train_data[idx].keys())\n",
    "print(\"ho\")\n",
    "print(train_data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745723f6-c7ca-4107-8f3a-0cd8f14627f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a0257-d95b-45e8-94f7-9cd63a9ed4e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.onnx.export(model, (tokens[\"input_ids\"], tokens[\"attention_mask\"]), onnx_model_path,\n",
    "                  export_params=True, opset_version=20,\n",
    "                  do_constant_folding=True, input_names=['input_ids', 'attention_mask'],\n",
    "                  output_names=['output'], \n",
    "                  dynamic_axes={\n",
    "                      \"input_ids\": {0: \"batch_size\"},\n",
    "                      \"attention_mask\": {0: \"batch_size\"},\n",
    "                      \"output\": {0: \"batch_size\"}\n",
    "                  }\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d14ef0-4058-4702-b475-8f45f817443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ONNX model saved to {onnx_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc4a64-68ca-49ad-be7f-79fce49ed0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(onnx_model_path)\n",
    "onnx.checker.check_model(onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e835aaf-0aae-4c82-b641-bf187717cb15",
   "metadata": {},
   "source": [
    "Creating an inference session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2876cc-418b-4ddc-ab2b-f54156397bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83222d30-cc4e-4d78-9ca1-1880688f01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session.get_providers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61f1485-f26a-49aa-a7aa-a8341cb93e4b",
   "metadata": {},
   "source": [
    "### Check Model Size of ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768711ad-dd1f-41fd-be5c-31794be473e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_size_in_bytes = os.path.getsize(onnx_model_path) \n",
    "model_size_gb = onnx_model_size_in_bytes / (1024 ** 3)\n",
    "model_size_mb = onnx_model_size_in_bytes / (1024 ** 2)\n",
    "# print(f\"ONNX model size: {model_size_gb:.5f} GiB, {model_size_mb:.5f} MiB\")\n",
    "print(f\"Model Size on Disk: {onnx_model_size_in_bytes/ (1e6) :.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad4e54-86b3-4bef-8520-be4468bfe10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the loaded pytorch model of 32 GB RAM to clear up space\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40c5a394-46d3-4de1-ad9d-14f05476a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23\n"
     ]
    }
   ],
   "source": [
    "print(f\"{os.path.getsize('./models')/(1e6):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe47d9c-2574-4800-9c04-481ad7f8251d",
   "metadata": {},
   "source": [
    "### Test accuracy on ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef7104a9-b63a-41bf-a68d-183f79d4700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:           503Gi       264Gi       106Gi        14Mi       136Gi       238Gi\n",
      "Swap:             0B          0B          0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "903839cd-ccdf-4e1b-9e58-206e9ad64d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 10 10:39:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off |   00000000:27:00.0 Off |                    0 |\n",
      "| N/A   62C    P0             79W /  300W |   68093MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16616b8e-f0aa-49db-a53b-9614af986f97",
   "metadata": {},
   "source": [
    "From the above, there's plenty of memory available in CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32306f0-a3e1-4954-8fc5-30a5b231947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-Coder-V2-Lite-Base\", trust_remote_code=True)\n",
    "onnx_model_path = \"models/finetunedDeepseekcoV2.onnx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4d28bdb-525f-4cda-a1a9-a0fa4bf3c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = test_data[:10]\n",
    "references = []\n",
    "predictions = []\n",
    "latencies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ea749e3-f3cf-45ee-8692-df7ae3f54830",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 1 Got: 383 Expected: 136\n Please fix either the inputs/outputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Measure Latency\u001b[39;00m\n\u001b[1;32m      8\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mort_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     15\u001b[0m latencies\u001b[38;5;241m.\u001b[39mappend(end \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:273\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    271\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 1 Got: 383 Expected: 136\n Please fix either the inputs/outputs or the model."
     ]
    }
   ],
   "source": [
    "for data in test_samples:\n",
    "    input_text = data[\"input\"]\n",
    "    reference_comment = data[\"input\"]\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"np\", padding=True, truncation=True)\n",
    "\n",
    "    # Measure Latency\n",
    "    start = time.time()\n",
    "    outputs = ort_session.run(None, {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"]\n",
    "    })\n",
    "    end = time.time()\n",
    "\n",
    "    latencies.append(end - start)\n",
    "\n",
    "    # generate text from ids\n",
    "    generated_ids = np.argmax(outputs[0], axis=-1)\n",
    "    generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    references.append(reference_comment)\n",
    "    predictions.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a20eb44-15c4-48d9-9af7-eacc26a01b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print([inp.name for inp in ort_session.get_inputs()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98398e-a83e-47ae-b086-5590b413dff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710aa532-5e36-4e52-a499-640b89c5b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deepseek-finetune\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d28e762-d73d-41e3-99a8-853790de7e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
